{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*Python 3.11.8 (any 3.11 should be fine), all packages in code blocks*"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## based on https://huggingface.co/spaces/nielsr/dit-document-layout-analysis/tree/main"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T16:02:05.672910Z",
     "start_time": "2024-03-31T16:00:43.464666Z"
    }
   },
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\r\n",
      "Collecting torch\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (819.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m819.2/819.2 MB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torchvision\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m63.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torchaudio\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hCollecting filelock (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.10.0)\r\n",
      "Collecting sympy (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/5.7 MB\u001B[0m \u001B[31m44.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting networkx (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m46.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.3)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.0/154.0 kB\u001B[0m \u001B[31m22.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.2/23.2 MB\u001B[0m \u001B[31m69.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m875.6/875.6 kB\u001B[0m \u001B[31m34.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m84.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m728.5/728.5 MB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m417.9/417.9 MB\u001B[0m \u001B[31m19.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.4/168.4 MB\u001B[0m \u001B[31m29.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.1/58.1 MB\u001B[0m \u001B[31m61.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.2/128.2 MB\u001B[0m \u001B[31m39.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m204.1/204.1 MB\u001B[0m \u001B[31m30.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nccl-cu11==2.19.3 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m135.3/135.3 MB\u001B[0m \u001B[31m29.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting triton==2.2.0 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m167.9/167.9 MB\u001B[0m \u001B[31m33.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting numpy (from torchvision)\r\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m72.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\r\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m54.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, fsspec, filelock, triton, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\r\n",
      "Successfully installed filelock-3.9.0 fsspec-2023.4.0 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 pillow-10.2.0 sympy-1.12 torch-2.2.2+cu118 torchaudio-2.2.2+cu118 torchvision-0.17.2+cu118 triton-2.2.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fDo9OJ7tP9H5",
    "ExecuteTime": {
     "end_time": "2024-03-31T16:34:20.778438Z",
     "start_time": "2024-03-31T16:34:09.333887Z"
    }
   },
   "source": [
    "!pip install pyyaml==5.1 numpy scipy shapely timm opencv-python Pillow git+https://github.com/huggingface/transformers.git sentencepiece"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-05hg92jk\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-05hg92jk\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 3b8e2932ce743008f63585aae1e1b8b30dc8b3ac\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting pyyaml==5.1\r\n",
      "  Using cached PyYAML-5.1-cp311-cp311-linux_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.26.3)\r\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (1.12.0)\r\n",
      "Requirement already satisfied: shapely in ./.venv/lib/python3.11/site-packages (2.0.3)\r\n",
      "Requirement already satisfied: timm in ./.venv/lib/python3.11/site-packages (0.9.16)\r\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.11/site-packages (4.9.0.80)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (10.2.0)\r\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.11/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (from timm) (2.2.2+cu118)\r\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.11/site-packages (from timm) (0.17.2+cu118)\r\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.11/site-packages (from timm) (0.22.2)\r\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.11/site-packages (from timm) (0.4.2)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (3.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (24.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (0.15.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (4.66.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.3.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (4.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\r\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch->timm) (1.12)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch->timm) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch->timm) (3.1.3)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.89)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.89)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.87)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in ./.venv/lib/python3.11/site-packages (from torch->timm) (8.7.0.84)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.11.3.6)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.venv/lib/python3.11/site-packages (from torch->timm) (10.9.0.58)\r\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in ./.venv/lib/python3.11/site-packages (from torch->timm) (10.3.0.86)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.4.1.48)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.7.5.86)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in ./.venv/lib/python3.11/site-packages (from torch->timm) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.86)\r\n",
      "Requirement already satisfied: triton==2.2.0 in ./.venv/lib/python3.11/site-packages (from torch->timm) (2.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\r\n",
      "Installing collected packages: pyyaml\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0.1\r\n",
      "    Uninstalling PyYAML-6.0.1:\r\n",
      "      Successfully uninstalled PyYAML-6.0.1\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyter-events 0.10.0 requires pyyaml>=5.3, but you have pyyaml 5.1 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed pyyaml-5.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yi9kvuR9LYQx",
    "outputId": "0d4100d6-b1af-4ce8-ce0c-243d6e8e641d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  fonts-freefont-ttf\n",
      "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
      "Need to get 2,388 kB of archives.\n",
      "After this operation, 6,653 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
      "Fetched 2,388 kB in 0s (5,329 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package fonts-freefont-ttf.\n",
      "(Reading database ... 121752 files and directories currently installed.)\n",
      "Preparing to unpack .../fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
      "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
      "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install fonts-freefont-ttf -y"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3ApdjlGnV4rM",
    "outputId": "76ee9eff-fe9f-441e-891c-05b1cb4bc0b0",
    "ExecuteTime": {
     "end_time": "2024-03-31T16:29:12.574035Z",
     "start_time": "2024-03-31T16:28:22.476687Z"
    }
   },
   "source": [
    "!pip install scipy shapely timm Pillow git+https://github.com/huggingface/transformers.git sentencepiece python-doctr[torch]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-aqam2g03\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-aqam2g03\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 3b8e2932ce743008f63585aae1e1b8b30dc8b3ac\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting scipy\r\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/d4/b8/7169935f9a2ea9e274ad8c21d6133d492079e6ebc3fc69a915c2375616b0/scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.4/60.4 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting shapely\r\n",
      "  Obtaining dependency information for shapely from https://files.pythonhosted.org/packages/0d/8f/4d3df127beac22a1fb9bcf9783d75550af805290476a29277c72494dcf73/shapely-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading shapely-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\r\n",
      "Collecting timm\r\n",
      "  Obtaining dependency information for timm from https://files.pythonhosted.org/packages/68/99/2018622d268f6017ddfa5ee71f070bad5d07590374793166baa102849d17/timm-0.9.16-py3-none-any.whl.metadata\r\n",
      "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (10.2.0)\r\n",
      "Collecting sentencepiece\r\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/fb/12/2f5c8d4764b00033cf1c935b702d3bb878d10be9f0b87f0253495832d85f/sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting python-doctr[torch]\r\n",
      "  Obtaining dependency information for python-doctr[torch] from https://files.pythonhosted.org/packages/13/4d/51816da51b32a8830a874d4cc8e7603d862642df27ea6ee7c083cc1047f6/python_doctr-0.8.1-py3-none-any.whl.metadata\r\n",
      "  Downloading python_doctr-0.8.1-py3-none-any.whl.metadata (33 kB)\r\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in ./.venv/lib/python3.11/site-packages (from scipy) (1.26.3)\r\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (from timm) (2.2.2+cu118)\r\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.11/site-packages (from timm) (0.17.2+cu118)\r\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from timm) (6.0.1)\r\n",
      "Collecting huggingface_hub (from timm)\r\n",
      "  Obtaining dependency information for huggingface_hub from https://files.pythonhosted.org/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl.metadata\r\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting safetensors (from timm)\r\n",
      "  Obtaining dependency information for safetensors from https://files.pythonhosted.org/packages/8e/cf/b32d236cc01429bf2827bd1d8d81fa5a34a6cc7fb3499506f5d1aa19dcb8/safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (3.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (24.0)\r\n",
      "Collecting regex!=2019.12.17 (from transformers==4.40.0.dev0)\r\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8d/6b/2f6478814954c07c04ba60b78d688d3d7bab10d786e0b6c1db607e4f6673/regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers==4.40.0.dev0) (2.31.0)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.40.0.dev0)\r\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/15/0b/c09b2c0dc688c82adadaa0d5080983de3ce920f4a5cbadb7eaa5302ad251/tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Collecting tqdm>=4.27 (from transformers==4.40.0.dev0)\r\n",
      "  Obtaining dependency information for tqdm>=4.27 from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\r\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting importlib-metadata (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for importlib-metadata from https://files.pythonhosted.org/packages/2d/0a/679461c511447ffaf176567d5c496d1de27cbe34a87df6677d7171b2fbd4/importlib_metadata-7.1.0-py3-none-any.whl.metadata\r\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting h5py<4.0.0,>=3.1.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for h5py<4.0.0,>=3.1.0 from https://files.pythonhosted.org/packages/1e/e9/61d7338e503d63d2ce733373fa86256614f579b173cf3d0571d4f46cb561/h5py-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading h5py-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\r\n",
      "Collecting opencv-python<5.0.0,>=4.5.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for opencv-python<5.0.0,>=4.5.0 from https://files.pythonhosted.org/packages/d9/64/7fdfb9386511cd6805451e012c537073a79a958a58795c4e602e538c388c/opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Collecting pypdfium2<5.0.0,>=4.0.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for pypdfium2<5.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/4e/98/4a7b5cd24569fceb90c31ac199278d6cef156f8e9edf8469011ac6bc0ec9/pypdfium2-4.28.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading pypdfium2-4.28.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.5/48.5 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting pyclipper<2.0.0,>=1.2.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for pyclipper<2.0.0,>=1.2.0 from https://files.pythonhosted.org/packages/43/64/9c8e0c7d96d32c63e38f92da92e4e38685e30773644d9dcb73d2325beb47/pyclipper-1.3.0.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading pyclipper-1.3.0.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\r\n",
      "Collecting langdetect<2.0.0,>=1.0.9 (from python-doctr[torch])\r\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m981.5/981.5 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting rapidfuzz<4.0.0,>=3.0.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for rapidfuzz<4.0.0,>=3.0.0 from https://files.pythonhosted.org/packages/4f/b7/2743e279c69c4efd0df153d0e68458ae1eba22e473a45f45b1e80b01e548/rapidfuzz-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading rapidfuzz-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting matplotlib>=3.1.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/ef/1d/bf1d78126c3d106100232d3a18b7f3732e7dc3b71ee38ab735e4064b19cc/matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\r\n",
      "Collecting weasyprint>=55.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for weasyprint>=55.0 from https://files.pythonhosted.org/packages/b7/f0/f313cee61f320b3c651dcc213767ff6eda0b4398fc04ceae8b4882b58b48/weasyprint-61.2-py3-none-any.whl.metadata\r\n",
      "  Downloading weasyprint-61.2-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: defusedxml>=0.7.0 in ./.venv/lib/python3.11/site-packages (from python-doctr[torch]) (0.7.1)\r\n",
      "Collecting mplcursors>=0.3 (from python-doctr[torch])\r\n",
      "  Downloading mplcursors-0.5.3.tar.gz (88 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m88.8/88.8 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Installing backend dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting unidecode>=1.0.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for unidecode>=1.0.0 from https://files.pythonhosted.org/packages/84/b7/6ec57841fb67c98f52fc8e4a2d96df60059637cba077edc569a302a8ffc7/Unidecode-1.3.8-py3-none-any.whl.metadata\r\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting onnx<3.0.0,>=1.12.0 (from python-doctr[torch])\r\n",
      "  Obtaining dependency information for onnx<3.0.0,>=1.12.0 from https://files.pythonhosted.org/packages/df/48/63f68b65d041aedffab41eea930563ca52aab70dbaa7d4820501618c1a70/onnx-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading onnx-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub->timm)\r\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl.metadata\r\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (4.10.0)\r\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.11/site-packages (from langdetect<2.0.0,>=1.0.9->python-doctr[torch]) (1.16.0)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/e2/83/29a63bbc72839cc6b24b5a0e3d004d4ed4e8439f26460ad9a34e39251904/contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\r\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/86/d0/06de6c883a2511c35bba400d0f6e42b8da0ff34123586cfb11213c9357df/fonttools-4.50.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading fonttools-4.50.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m159.4/159.4 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/17/ba/17a706b232308e65f57deeccae503c268292e6a091313f6ce833a23093ea/kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/9d/ea/6d76df31432a0e6fdf81681a895f009a4bb47b3c39036db3e1b528191d52/pyparsing-3.1.2-py3-none-any.whl.metadata\r\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.1.0->python-doctr[torch]) (2.9.0.post0)\r\n",
      "Collecting protobuf>=3.20.2 (from onnx<3.0.0,>=1.12.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for protobuf>=3.20.2 from https://files.pythonhosted.org/packages/2c/2a/d2741cad35fa5f06d9c59dda3274e5727ca11075dfd7de3f69c100efdcad/protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\r\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch->timm) (1.12)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch->timm) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch->timm) (3.1.3)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.89)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.89)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.87)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in ./.venv/lib/python3.11/site-packages (from torch->timm) (8.7.0.84)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.11.3.6)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.venv/lib/python3.11/site-packages (from torch->timm) (10.9.0.58)\r\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in ./.venv/lib/python3.11/site-packages (from torch->timm) (10.3.0.86)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.4.1.48)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.7.5.86)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in ./.venv/lib/python3.11/site-packages (from torch->timm) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in ./.venv/lib/python3.11/site-packages (from torch->timm) (11.8.86)\r\n",
      "Requirement already satisfied: triton==2.2.0 in ./.venv/lib/python3.11/site-packages (from torch->timm) (2.2.0)\r\n",
      "Collecting pydyf>=0.8.0 (from weasyprint>=55.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for pydyf>=0.8.0 from https://files.pythonhosted.org/packages/b1/66/7bc6bfcf220b74875cc362e29d265924e2506dfe305bb4b1365f43b1c594/pydyf-0.9.0-py3-none-any.whl.metadata\r\n",
      "  Downloading pydyf-0.9.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: cffi>=0.6 in ./.venv/lib/python3.11/site-packages (from weasyprint>=55.0->python-doctr[torch]) (1.16.0)\r\n",
      "Collecting html5lib>=1.1 (from weasyprint>=55.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for html5lib>=1.1 from https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: tinycss2>=1.0.0 in ./.venv/lib/python3.11/site-packages (from weasyprint>=55.0->python-doctr[torch]) (1.2.1)\r\n",
      "Collecting cssselect2>=0.1 (from weasyprint>=55.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for cssselect2>=0.1 from https://files.pythonhosted.org/packages/9d/3a/e39436efe51894243ff145a37c4f9a030839b97779ebcc4f13b3ba21c54e/cssselect2-0.7.0-py3-none-any.whl.metadata\r\n",
      "  Downloading cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting Pyphen>=0.9.1 (from weasyprint>=55.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for Pyphen>=0.9.1 from https://files.pythonhosted.org/packages/e3/c3/556e4ed0402ad7810a828532d539f1b14884fc0ff6c2da8ab401bf3bbd63/pyphen-0.14.0-py3-none-any.whl.metadata\r\n",
      "  Downloading pyphen-0.14.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting zipp>=0.5 (from importlib-metadata->python-doctr[torch])\r\n",
      "  Obtaining dependency information for zipp>=0.5 from https://files.pythonhosted.org/packages/c2/0a/ba9d0ee9536d3ef73a3448e931776e658b36f128d344e175bc32b092a8bf/zipp-3.18.1-py3-none-any.whl.metadata\r\n",
      "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\r\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=0.6->weasyprint>=55.0->python-doctr[torch]) (2.22)\r\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.11/site-packages (from cssselect2>=0.1->weasyprint>=55.0->python-doctr[torch]) (0.5.1)\r\n",
      "Collecting zopfli>=0.1.4 (from fonttools>=4.22.0->matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for zopfli>=0.1.4 from https://files.pythonhosted.org/packages/b9/7c/c4145c0c10e765275d957877ffb4b4d741b3f805324c8d54cce8cd546c5c/zopfli-0.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading zopfli-0.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\r\n",
      "Collecting brotli>=1.0.1 (from fonttools>=4.22.0->matplotlib>=3.1.0->python-doctr[torch])\r\n",
      "  Obtaining dependency information for brotli>=1.0.1 from https://files.pythonhosted.org/packages/b3/e7/ca2993c7682d8629b62630ebf0d1f3bb3d579e667ce8e7ca03a0a0576a2d/Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\r\n",
      "Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.4/38.4 MB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0mm0:01\u001B[0m\r\n",
      "\u001B[?25hDownloading shapely-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m11.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m12.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading h5py-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.8/4.8 MB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m388.9/388.9 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.6/11.6 MB\u001B[0m \u001B[31m12.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading onnx-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.9/15.9 MB\u001B[0m \u001B[31m14.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.2/62.2 MB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyclipper-1.3.0.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (971 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m971.5/971.5 kB\u001B[0m \u001B[31m15.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pypdfium2-4.28.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m13.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading rapidfuzz-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m16.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m785.1/785.1 kB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m14.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m16.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 kB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m235.5/235.5 kB\u001B[0m \u001B[31m18.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading weasyprint-61.2-py3-none-any.whl (271 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m271.5/271.5 kB\u001B[0m \u001B[31m25.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\r\n",
      "Downloading python_doctr-0.8.1-py3-none-any.whl (295 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m295.0/295.0 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m313.4/313.4 kB\u001B[0m \u001B[31m15.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\r\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.50.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.9/4.9 MB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m172.0/172.0 kB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m112.2/112.2 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m302.8/302.8 kB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pydyf-0.9.0-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m103.2/103.2 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\r\n",
      "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading zopfli-0.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (850 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m850.5/850.5 kB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: transformers, langdetect, mplcursors\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8796955 sha256=540d79034d13fd4931b747bed640d431e8b28dfb578ca1829bb5604a925b6518\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6dh54s_0/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\r\n",
      "  Building wheel for langdetect (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=5acc7bdb590f639c7f2a4d1cfc3062b852922583797c881a1cb72c862dbbb5c5\r\n",
      "  Stored in directory: /home/akos/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\r\n",
      "  Building wheel for mplcursors (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for mplcursors: filename=mplcursors-0.5.3-py3-none-any.whl size=20728 sha256=b4fce5c6c44c4889519712bd7ec86161cff78d639ca9af87abbad49a930c1bab\r\n",
      "  Stored in directory: /home/akos/.cache/pip/wheels/10/b6/58/05d5160d055ea77855fc4324d32a33f9ddea3e5289f315e738\r\n",
      "Successfully built transformers langdetect mplcursors\r\n",
      "Installing collected packages: sentencepiece, pyclipper, brotli, zopfli, zipp, unidecode, tqdm, shapely, scipy, safetensors, regex, rapidfuzz, Pyphen, pypdfium2, pyparsing, pydyf, protobuf, opencv-python, langdetect, kiwisolver, html5lib, h5py, fsspec, fonttools, cycler, contourpy, onnx, matplotlib, importlib-metadata, huggingface_hub, cssselect2, weasyprint, tokenizers, mplcursors, transformers, timm, python-doctr\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2023.4.0\r\n",
      "    Uninstalling fsspec-2023.4.0:\r\n",
      "      Successfully uninstalled fsspec-2023.4.0\r\n",
      "Successfully installed Pyphen-0.14.0 brotli-1.1.0 contourpy-1.2.0 cssselect2-0.7.0 cycler-0.12.1 fonttools-4.50.0 fsspec-2024.3.1 h5py-3.10.0 html5lib-1.1 huggingface_hub-0.22.2 importlib-metadata-7.1.0 kiwisolver-1.4.5 langdetect-1.0.9 matplotlib-3.8.3 mplcursors-0.5.3 onnx-1.16.0 opencv-python-4.9.0.80 protobuf-5.26.1 pyclipper-1.3.0.post5 pydyf-0.9.0 pyparsing-3.1.2 pypdfium2-4.28.0 python-doctr-0.8.1 rapidfuzz-3.7.0 regex-2023.12.25 safetensors-0.4.2 scipy-1.12.0 sentencepiece-0.2.0 shapely-2.0.3 timm-0.9.16 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.40.0.dev0 unidecode-1.3.8 weasyprint-61.2 zipp-3.18.1 zopfli-0.2.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjeZVIJiYYsX",
    "outputId": "9834a934-de4b-4aca-a318-e3e3c0c92ee1",
    "ExecuteTime": {
     "end_time": "2024-03-31T16:35:31.570636Z",
     "start_time": "2024-03-31T16:35:27.118097Z"
    }
   },
   "source": [
    "!git clone https://github.com/facebookresearch/detectron2.git"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'detectron2'...\r\n",
      "remote: Enumerating objects: 15526, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (251/251), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (197/197), done.\u001B[K\r\n",
      "remote: Total 15526 (delta 80), reused 194 (delta 54), pack-reused 15275\u001B[Kects:  37% (5745/15526), 2.61 MiB | 1.28 MiB/sReceiving objects:  39% (6056/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  42% (6521/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  47% (7298/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  49% (7608/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  53% (8229/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  56% (8695/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  60% (9316/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  62% (9627/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  65% (10092/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  70% (10869/15526), 4.04 MiB | 1.58 MiB/sReceiving objects:  75% (11645/15526), 5.59 MiB | 1.83 MiB/sReceiving objects:  80% (12421/15526), 5.59 MiB | 1.83 MiB/sReceiving objects:  88% (13663/15526), 5.59 MiB | 1.83 MiB/sReceiving objects:  92% (14284/15526), 5.59 MiB | 1.83 MiB/sReceiving objects:  99% (15371/15526), 5.59 MiB | 1.83 MiB/s\r\n",
      "Receiving objects: 100% (15526/15526), 6.40 MiB | 1.91 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11195/11195), done.\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ruKsMKRdYcV8",
    "outputId": "6733891b-953a-46b9-b318-31ef4f85299b",
    "ExecuteTime": {
     "end_time": "2024-04-01T12:49:44.294461Z",
     "start_time": "2024-04-01T12:49:40.742239Z"
    }
   },
   "source": [
    "!pip install -e detectron2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/akos/PycharmProjects/Printed-OCR/detectron2\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: Pillow>=7.1 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (10.2.0)\r\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (3.8.3)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (2.0.7)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (2.4.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.8 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (0.1.8)\r\n",
      "Requirement already satisfied: tabulate in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (0.9.0)\r\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (3.0.0)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (4.66.2)\r\n",
      "Requirement already satisfied: tensorboard in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (2.16.2)\r\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (0.1.5.post20221221)\r\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (0.1.9)\r\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (2.3.0)\r\n",
      "Requirement already satisfied: hydra-core>=1.1 in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (1.3.2)\r\n",
      "Requirement already satisfied: black in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (24.3.0)\r\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from detectron2==0.6) (24.0)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./.venv/lib/python3.11/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\r\n",
      "Requirement already satisfied: portalocker in ./.venv/lib/python3.11/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.8.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (4.50.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.11/site-packages (from black->detectron2==0.6) (8.1.7)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./.venv/lib/python3.11/site-packages (from black->detectron2==0.6) (1.0.0)\r\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.11/site-packages (from black->detectron2==0.6) (0.12.1)\r\n",
      "Requirement already satisfied: platformdirs>=2 in ./.venv/lib/python3.11/site-packages (from black->detectron2==0.6) (4.2.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (2.1.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.62.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (3.6)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (5.26.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (68.2.0)\r\n",
      "Requirement already satisfied: six>1.9 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard->detectron2==0.6) (3.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\r\n",
      "Installing collected packages: detectron2\r\n",
      "  Attempting uninstall: detectron2\r\n",
      "    Found existing installation: detectron2 0.6\r\n",
      "    Not uninstalling detectron2 at /home/akos/PycharmProjects/Printed-OCR/detectron2, outside environment /home/akos/PycharmProjects/Printed-OCR/.venv\r\n",
      "    Can't uninstall 'detectron2'. No files were found to uninstall.\r\n",
      "  Running setup.py develop for detectron2\r\n",
      "Successfully installed detectron2-0.6\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtrV0tmLYh_x",
    "outputId": "97a6726b-db23-4afb-d300-d055b16a2f45",
    "ExecuteTime": {
     "end_time": "2024-03-31T16:35:20.318490Z",
     "start_time": "2024-03-31T16:35:13.026545Z"
    }
   },
   "source": [
    "!git clone https://github.com/microsoft/unilm.git"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'unilm'...\r\n",
      "remote: Enumerating objects: 9860, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (149/149), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (96/96), done.\u001B[K\r\n",
      "remote: Total 9860 (delta 59), reused 122 (delta 47), pack-reused 9711\u001B[K\r\n",
      "Receiving objects: 100% (9860/9860), 58.69 MiB | 9.90 MiB/s, done.\r\n",
      "Resolving deltas: 100% (4610/4610), done.\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T19:30:38.054392Z",
     "start_time": "2024-04-01T19:30:31.496186Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pyspellchecker",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\r\n",
      "  Obtaining dependency information for pyspellchecker from https://files.pythonhosted.org/packages/e1/d2/c7e3b3a61a34b9320399fa731d1f9f0c73db8a1f28c6764e9e11efa68a29/pyspellchecker-0.8.1-py3-none-any.whl.metadata\r\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.8/6.8 MB\u001B[0m \u001B[31m29.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1. Document layout analysis: determine where are text blocks in document, which block is text which is math"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Download model from https://1drv.ms/u/s!Av3x-YhV4OQQuWJEUmn2iCrfEe_A?e=EdbhzB put it besides notebook"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T10:56:28.743068Z",
     "start_time": "2024-04-28T10:56:28.237931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "#cv2_imshow(img)\n",
    "img = cv2.imread(\"test.png\", cv2.IMREAD_COLOR)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L0BB0KtORUtk",
    "outputId": "1b545a2b-8e57-4c0d-dd0d-059464831e6e",
    "ExecuteTime": {
     "end_time": "2024-04-28T11:19:27.782263Z",
     "start_time": "2024-04-28T11:19:18.441661Z"
    }
   },
   "source": [
    "import os\n",
    "os.system(\"sed -i 's/from collections import Iterable/from collections.abc import Iterable/' unilm/dit/object_detection/ditod/table_evaluation/data_structure.py\")\n",
    "#os.system(\"curl -LJ -o publaynet_dit-b_cascade.pth 'https://layoutlm.blob.core.windows.net/dit/dit-fts/publaynet_dit-b_cascade.pth?sv=2022-11-02&ss=b&srt=o&sp=r&se=2033-06-08T16:48:15Z&st=2023-06-08T08:48:15Z&spr=https&sig=a9VXrihTzbWyVfaIDlIT1Z0FoR1073VB0RLQUMuudD4%3D'\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"unilm\")\n",
    "sys.path.append(\"detectron2\")\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import requests\n",
    "from PIL import Image\n",
    "from unilm.dit.object_detection.ditod import add_vit_config\n",
    "\n",
    "import torch\n",
    "\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor\n",
    "import os\n",
    "\n",
    "# instantiate config\n",
    "cfg = get_cfg()\n",
    "add_vit_config(cfg)\n",
    "cfg.merge_from_file(\"cascade_dit_base.yml\")\n",
    "\n",
    "\n",
    "# load local model\n",
    "WORKING_DIR = os.path.abspath(os.getcwd())\n",
    "print( f\"{WORKING_DIR}/layout.pth\")\n",
    "cfg.merge_from_list([\"MODEL.WEIGHTS\", f\"{WORKING_DIR}/layout.pth\"])\n",
    "# Step 2: add model weights URL to config\n",
    "cfg.MODEL.WEIGHTS = f\"{WORKING_DIR}/layout.pth\"\n",
    "\n",
    "\n",
    "\n",
    "# set device\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# define model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "def analyze_image(img):\n",
    "    md = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "    # defining the classes for classifing the text block\n",
    "    if cfg.DATASETS.TEST[0]=='icdar2019_test':\n",
    "        md.set(thing_classes=[\"table\"])\n",
    "    else:\n",
    "        md.set(thing_classes=[\"text\",\"title\",\"list\",\"table\",\"figure\"])\n",
    "    # run classification\n",
    "    output = predictor(img)[\"instances\"]\n",
    "    v = Visualizer(img[:, :, ::-1],\n",
    "                    md,\n",
    "                    scale=1.0,\n",
    "                    instance_mode=ColorMode.SEGMENTATION)\n",
    "    result = v.draw_instance_predictions(output.to(\"cpu\"))\n",
    "    result_image = result.get_image()[:, :, ::-1]\n",
    "\n",
    "    return (result_image,output)\n",
    "\n",
    "\n",
    "analysis=analyze_image(img)\n",
    "# saving result\n",
    "cv2.imwrite(\"analysis_res.png\", analysis[0])\n",
    "print(analysis[1])\n",
    "#cv2_imshow(analysis[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akos/PycharmProjects/Printed-OCR/layout.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/akos/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances(num_instances=15, image_height=832, image_width=725, fields=[pred_boxes: Boxes(tensor([[120.6347, 423.9032, 581.5430, 551.2037],\n",
      "        [120.4088, 576.0052, 581.4291, 623.4697],\n",
      "        [120.5843, 682.4244, 581.7710, 760.8268],\n",
      "        [120.8733, 191.0161, 581.6189, 270.3373],\n",
      "        [120.8086, 368.3006, 581.4935, 399.4764],\n",
      "        [141.7956, 762.1523, 517.9915, 777.3322],\n",
      "        [120.3710,  73.0476, 545.2736,  88.3567],\n",
      "        [120.8382, 647.4643, 448.2783, 666.1872],\n",
      "        [133.1432, 789.0068, 292.7106, 804.2065],\n",
      "        [161.6769, 281.8311, 581.5131, 356.3529],\n",
      "        [224.6340, 101.9860, 478.9942, 180.1516],\n",
      "        [564.6368, 101.5246, 581.0156, 118.0061],\n",
      "        [132.7957, 789.0318, 292.7639, 804.0854],\n",
      "        [564.5613, 122.7856, 581.2941, 137.7977],\n",
      "        [224.5607, 101.9069, 479.7011, 180.1294]], device='cuda:0')), scores: tensor([0.9990, 0.9986, 0.9985, 0.9976, 0.9961, 0.9945, 0.9915, 0.9795, 0.7552,\n",
      "        0.4204, 0.1100, 0.0917, 0.0661, 0.0594, 0.0514], device='cuda:0'), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 1, 2, 4, 3, 0, 0, 0, 4], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]], device='cuda:0')])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJaLtvh2bhxs",
    "outputId": "0efbba1e-89c2-4558-b8aa-5965914f2b92",
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:10.334892Z",
     "start_time": "2024-04-28T11:42:10.317490Z"
    }
   },
   "source": [
    "preds=analysis[1]\n",
    "# saving the indexes of math blocks and text blocks into arrays\n",
    "math_indexes=[]\n",
    "text_indexes=[]\n",
    "\n",
    "\n",
    "math_images = []\n",
    "text_images= []\n",
    "\n",
    "for i in range(0,len(preds.pred_classes)):\n",
    "  if(preds.pred_classes[i].item() == 4 or preds.pred_classes[i].item() == 3):\n",
    "    math_indexes.append(i)\n",
    "  else:\n",
    "    text_indexes.append(i)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:13.527765Z",
     "start_time": "2024-04-28T11:42:13.522096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# making folder where images of blocks will be saved\n",
    "if not os.path.isdir(\"./All_blocks\"):\n",
    "    os.mkdir(\"./All_blocks\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:16.577428Z",
     "start_time": "2024-04-28T11:42:16.553969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting the bounding box of every math image and croping and saving the image\n",
    "for math_index in math_indexes:\n",
    "  bounding_box = preds.pred_boxes[math_index].tensor.cpu().numpy()[0]\n",
    "  print(bounding_box)\n",
    "  cropped_image = img[int(bounding_box[1]):int(bounding_box[3]), int(bounding_box[0]):int(bounding_box[2])]\n",
    "  math_images.append((cropped_image,bounding_box))\n",
    "  # Save the cropped image\n",
    "  cv2.imwrite(f\"./All_blocks/{math_index}_cropped_image_math.jpg\", cropped_image)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161.6769  281.83105 581.5131  356.35287]\n",
      "[224.63405 101.98597 478.99423 180.15158]\n",
      "[224.56068 101.90694 479.7011  180.12944]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:22.378440Z",
     "start_time": "2024-04-28T11:42:22.314623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting the bounding box of every text image and croping and saving the image\n",
    "for text_index in text_indexes:\n",
    "  bounding_box = preds.pred_boxes[text_index].tensor.cpu().numpy()[0]\n",
    "  print(bounding_box)\n",
    "  cropped_image = img[int(bounding_box[1]):int(bounding_box[3]), int(bounding_box[0]):int(bounding_box[2])]\n",
    "  text_images.append((cropped_image,bounding_box))\n",
    "  # Save the cropped image\n",
    "  cv2.imwrite(f\"./All_blocks/{text_index}_cropped_image_text.jpg\", cropped_image)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120.63466 423.9032  581.543   551.2037 ]\n",
      "[120.40883 576.0052  581.42914 623.4697 ]\n",
      "[120.58427 682.4244  581.771   760.82684]\n",
      "[120.873276 191.01611  581.6189   270.33734 ]\n",
      "[120.80859 368.3006  581.4935  399.4764 ]\n",
      "[141.79561 762.1523  517.9915  777.3322 ]\n",
      "[120.370964  73.04762  545.27356   88.35667 ]\n",
      "[120.83821 647.4643  448.27826 666.1872 ]\n",
      "[133.14322 789.0068  292.71063 804.2065 ]\n",
      "[564.63684  101.524574 581.0156   118.00608 ]\n",
      "[132.79565 789.0318  292.76395 804.0854 ]\n",
      "[564.5613   122.785614 581.29407  137.79773 ]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2 line segmention: assign bounding box to every word in every block using DocTR"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wyW5uL5BMjLH",
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:33.832558Z",
     "start_time": "2024-04-28T11:42:27.084729Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import io\n",
    "from PIL import Image\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Let's pick the desired backend\n",
    "# os.environ['USE_TF'] = '1'\n",
    "os.environ['USE_TORCH'] = '1'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import ImageDraw,Image\n",
    "import matplotlib.pyplot as plt\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "def split_text_by_lines(img):\n",
    "    def convert_coordinates(geometry, page_dim):\n",
    "        # black magic to convert cv2 coordinates to docTR coordinates\n",
    "        len_x = page_dim[1]\n",
    "        len_y = page_dim[0]\n",
    "        (x_min, y_min) = geometry[0]\n",
    "        (x_max, y_max) = geometry[1]\n",
    "        x_min = math.floor(x_min * len_x)\n",
    "        x_max = math.ceil(x_max * len_x)\n",
    "        y_min = math.floor(y_min * len_y)\n",
    "        y_max = math.ceil(y_max * len_y)\n",
    "        return [x_min, x_max, y_min, y_max]\n",
    "    def get_coordinates(output):\n",
    "        page_dim = output['pages'][0][\"dimensions\"]\n",
    "        text_coordinates = []\n",
    "        for obj1 in output['pages'][0][\"blocks\"]:\n",
    "            for obj2 in obj1[\"lines\"]:\n",
    "                for obj3 in obj2[\"words\"]:\n",
    "                    converted_coordinates = convert_coordinates(\n",
    "                                            obj3[\"geometry\"],page_dim\n",
    "                                            )\n",
    "                    text_coordinates.append((converted_coordinates, obj3[\"value\"]))\n",
    "        return text_coordinates\n",
    "    def get_imgs(img, bound):\n",
    "        imgs= []\n",
    "        for b in bound:\n",
    "            p0, p1, p2, p3 = [b[0][0],b[0][2]], [b[0][1],b[0][2]], \\\n",
    "                          [b[0][1],b[0][3]], [b[0][0],b[0][3]]\n",
    "            crop = img[p0[1]:p2[1], p0[0]:p2[0]]\n",
    "            #cv2_imshow(crop)\n",
    "            imgs.append(crop)\n",
    "        return imgs\n",
    "\n",
    "    # DocTR does not read from cv2 image so save img first and load img with DocumentFile.from_images\n",
    "    cv2.imwrite(\"lines.png\", img)\n",
    "    doc=DocumentFile.from_images(\"lines.png\")\n",
    "    \n",
    "    # Do ocr on image block to get bounding box\n",
    "    predictor = ocr_predictor(pretrained=True)\n",
    "    result = predictor(doc)\n",
    "    result.show()\n",
    "    export = result.export()\n",
    "    \n",
    "    # get bounding box from ocr result\n",
    "    bounding_boxes = get_coordinates(export)\n",
    "    # crop image by bounding box\n",
    "    imgs = get_imgs(img, bounding_boxes)\n",
    "    return imgs"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:40.595098Z",
     "start_time": "2024-04-28T11:42:40.590493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DocumentBlock:\n",
    "    def __init__(self,is_math:bool,latex_code:str,bounding_box:list):\n",
    "        self.is_math = is_math\n",
    "        self.latex_code = latex_code\n",
    "        self.bounding_box = bounding_box      "
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nougat-latex-ocr'...\r\n",
      "remote: Enumerating objects: 113, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (113/113), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (93/93), done.\u001B[K\r\n",
      "remote: Total 113 (delta 32), reused 83 (delta 11), pack-reused 0\u001B[K\r\n",
      "Receiving objects: 100% (113/113), 117.90 KiB | 2.46 MiB/s, done.\r\n",
      "Resolving deltas: 100% (32/32), done.\r\n"
     ]
    }
   ],
   "execution_count": 14,
   "source": "!git clone https://github.com/NormXU/nougat-latex-ocr"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:42:46.342145Z",
     "start_time": "2024-04-28T11:42:46.332488Z"
    }
   },
   "cell_type": "code",
   "source": "%cd ./nougat-latex-ocr",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akos/PycharmProjects/Printed-OCR/nougat-latex-ocr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akos/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 3 get latex code from math blocks"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:43:39.360768Z",
     "start_time": "2024-04-28T11:43:25.114970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "from transformers.models.nougat import NougatTokenizerFast\n",
    "from nougat_latex import NougatLaTexProcessor\n",
    "\n",
    "model_name = \"Norm/nougat-latex-base\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# init model\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name, cache_dir=\".\").to(device)\n",
    "\n",
    "# init processor\n",
    "tokenizer = NougatTokenizerFast.from_pretrained(model_name,cache_dir=\".\")\n",
    "\n",
    "latex_processor = NougatLaTexProcessor.from_pretrained(model_name)\n",
    "\n",
    "# run test\n",
    "def image_to_latex(image):\n",
    "    if not image.mode == \"RGB\":\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    pixel_values = latex_processor(image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    decoder_input_ids = tokenizer(tokenizer.bos_token, add_special_tokens=False,\n",
    "                                  return_tensors=\"pt\").input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            pixel_values.to(device),\n",
    "            decoder_input_ids=decoder_input_ids.to(device),\n",
    "            max_length=model.decoder.config.max_length,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=5,\n",
    "            bad_words_ids=[[tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "    sequence = tokenizer.batch_decode(outputs.sequences)[0]\n",
    "    sequence = sequence.replace(tokenizer.eos_token, \"\").replace(tokenizer.pad_token, \"\").replace(tokenizer.bos_token, \"\")\n",
    "    return sequence\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4: Do ocr on words from the text blocks and do spellcheck to correct mistakes (spellcheck is buggy at  the moment)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:46:55.780100Z",
     "start_time": "2024-04-28T11:46:45.669751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\",cache_dir=\".\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\",cache_dir=\".\")\n",
    "\n",
    "def do_spellcheck(word:str):\n",
    "    # TODO: account for additional characters when checking and keep them\n",
    "    is_misspelled = spell.unknown([word])[0]\n",
    "    if is_misspelled:\n",
    "        word = spell.correction(word)\n",
    "    return word\n",
    "def display_img(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #plt.imshow(gray)\n",
    "    #plt.title('my picture')\n",
    "    #plt.show()\n",
    "\n",
    "def process_image(image):\n",
    "    # prepare image\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return generated_text"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Do step 2-4 on math and text blocks (bug: math block imsgae should be 384x384 but sometimes its smaller somehow needs to resized)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T12:26:30.044092Z",
     "start_time": "2024-04-28T12:26:29.668725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import Text\n",
    "# you can put local path here for model but this will downlaoded once than chache it\n",
    "import random\n",
    "\n",
    "blocks = []\n",
    "for item in math_images:\n",
    "    math_image = item[0]\n",
    "    bounding_box = item[1]\n",
    "    cropped_image = img[int(bounding_box[1]):int(bounding_box[3]), int(bounding_box[0]):int(bounding_box[2])]\n",
    "    img = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "    im_pil = Image.fromarray(cropped_image)\n",
    "    latex = image_to_latex(im_pil)\n",
    "    print(latex)\n",
    "    block = DocumentBlock(is_math=True,latex_code=latex,bounding_box=bounding_box)\n",
    "    blocks.append(block)\n",
    "    \n",
    "for item in text_images:\n",
    "    text_image = item[0]\n",
    "    bounding_box = item[1]\n",
    "    print(\"-----------\")\n",
    "    #display_img(text_image)\n",
    "    #cv2_imshow(text_image)\n",
    "    lines = split_text_by_lines(text_image)\n",
    "    texts = []\n",
    "    for line in lines:\n",
    "        if line.shape[0] > 2: # avoid 1 pixel lines\n",
    "            #color_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            resp = process_image(line)\n",
    "            print(\"Result:\")\n",
    "            print(resp)\n",
    "            #word = do_spellcheck(resp)\n",
    "            texts.append(resp)\n",
    "            #print(word)\n",
    "    latex_string = ' '.join(texts)\n",
    "    block = DocumentBlock(is_math=False,latex_code=latex_string,bounding_box= bounding_box)\n",
    "    blocks.append(block)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input image size (224*560) doesn't match model (384*384).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(cropped_image, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[1;32m     11\u001B[0m im_pil \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(cropped_image)\n\u001B[0;32m---> 12\u001B[0m latex \u001B[38;5;241m=\u001B[39m \u001B[43mimage_to_latex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim_pil\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(latex)\n\u001B[1;32m     14\u001B[0m block \u001B[38;5;241m=\u001B[39m DocumentBlock(is_math\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,latex_code\u001B[38;5;241m=\u001B[39mlatex,bounding_box\u001B[38;5;241m=\u001B[39mbounding_box)\n",
      "Cell \u001B[0;32mIn[13], line 27\u001B[0m, in \u001B[0;36mimage_to_latex\u001B[0;34m(image)\u001B[0m\n\u001B[1;32m     24\u001B[0m decoder_input_ids \u001B[38;5;241m=\u001B[39m tokenizer(tokenizer\u001B[38;5;241m.\u001B[39mbos_token, add_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     25\u001B[0m                               return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39minput_ids\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 27\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_beams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbad_words_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munk_token_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m sequence \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(outputs\u001B[38;5;241m.\u001B[39msequences)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     40\u001B[0m sequence \u001B[38;5;241m=\u001B[39m sequence\u001B[38;5;241m.\u001B[39mreplace(tokenizer\u001B[38;5;241m.\u001B[39meos_token, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(tokenizer\u001B[38;5;241m.\u001B[39mpad_token, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(tokenizer\u001B[38;5;241m.\u001B[39mbos_token, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1398\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1390\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m   1391\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1392\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration results, please set `padding_side=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m` when initializing the tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1393\u001B[0m         )\n\u001B[1;32m   1395\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m model_kwargs:\n\u001B[1;32m   1396\u001B[0m     \u001B[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001B[39;00m\n\u001B[1;32m   1397\u001B[0m     \u001B[38;5;66;03m# and added to `model_kwargs`\u001B[39;00m\n\u001B[0;32m-> 1398\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_encoder_decoder_kwargs_for_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1399\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_input_name\u001B[49m\n\u001B[1;32m   1400\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1402\u001B[0m \u001B[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001B[39;00m\n\u001B[1;32m   1403\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder:\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:505\u001B[0m, in \u001B[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001B[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001B[0m\n\u001B[1;32m    503\u001B[0m encoder_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    504\u001B[0m encoder_kwargs[model_input_name] \u001B[38;5;241m=\u001B[39m inputs_tensor\n\u001B[0;32m--> 505\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]: ModelOutput \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mencoder_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/transformers/models/vit/modeling_vit.py:570\u001B[0m, in \u001B[0;36mViTModel.forward\u001B[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001B[0m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pixel_values\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m expected_dtype:\n\u001B[1;32m    568\u001B[0m     pixel_values \u001B[38;5;241m=\u001B[39m pixel_values\u001B[38;5;241m.\u001B[39mto(expected_dtype)\n\u001B[0;32m--> 570\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbool_masked_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbool_masked_pos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolate_pos_encoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolate_pos_encoding\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    574\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m    575\u001B[0m     embedding_output,\n\u001B[1;32m    576\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    580\u001B[0m )\n\u001B[1;32m    581\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/transformers/models/vit/modeling_vit.py:119\u001B[0m, in \u001B[0;36mViTEmbeddings.forward\u001B[0;34m(self, pixel_values, bool_masked_pos, interpolate_pos_encoding)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    114\u001B[0m     pixel_values: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m    115\u001B[0m     bool_masked_pos: Optional[torch\u001B[38;5;241m.\u001B[39mBoolTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    116\u001B[0m     interpolate_pos_encoding: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    117\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m    118\u001B[0m     batch_size, num_channels, height, width \u001B[38;5;241m=\u001B[39m pixel_values\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m--> 119\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolate_pos_encoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolate_pos_encoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bool_masked_pos \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    122\u001B[0m         seq_length \u001B[38;5;241m=\u001B[39m embeddings\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Printed-OCR/.venv/lib/python3.11/site-packages/transformers/models/vit/modeling_vit.py:174\u001B[0m, in \u001B[0;36mViTPatchEmbeddings.forward\u001B[0;34m(self, pixel_values, interpolate_pos_encoding)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m interpolate_pos_encoding:\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m height \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_size[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m width \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_size[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m--> 174\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    175\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput image size (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mheight\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m*\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwidth\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt match model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    176\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_size[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m*\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_size[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    177\u001B[0m         )\n\u001B[1;32m    178\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprojection(pixel_values)\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings\n",
      "\u001B[0;31mValueError\u001B[0m: Input image size (224*560) doesn't match model (384*384)."
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Step 5 assemble latex document (does  not work well, feel free to expirement with soemthing different :) )"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T12:24:14.297090Z",
     "start_time": "2024-04-28T12:24:14.288533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def order_blocks(blocks:List[DocumentBlock]):\n",
    "    # order by y axis\n",
    "    sorted(blocks, key=lambda x: x.bounding_box[1])\n",
    "    return  blocks\n",
    "\n",
    "def add_blocks_to_latex(blocks:List[DocumentBlock]):\n",
    "    blocks_string = \"\"\n",
    "    for block in blocks:    \n",
    "        blocks_string+=block.latex_code+\"\\n\"\n",
    "\n",
    "    latex_template = \"\"\"\n",
    "    \\\\documentclass{article}\n",
    "    \\\\usepackage{graphicx}\n",
    "    \\\\graphicspath{./imgs/}\n",
    "    \\\\noindent\n",
    "    \\\\begin{document}\n",
    "\n",
    "    \"\"\"+f\"\"\"\n",
    "    {blocks_string}\n",
    "    \"\"\"+\"\"\"\n",
    "    \\\\end{document}\n",
    "    \"\"\"\n",
    "    return latex_template"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T12:24:16.592252Z",
     "start_time": "2024-04-28T12:24:16.513744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DOC_WIDTH = 595\n",
    "DOC_HEIGHT = 842\n",
    "\n",
    "img = cv2.imread(\"../test.png\")\n",
    "height, width, channels = img.shape\n",
    "# calculate difference between actual document and A4 page size (used for space between paragraphs)\n",
    "width_percent = width/DOC_WIDTH\n",
    "height_percent = height/DOC_HEIGHT\n",
    "\n",
    "final_blocks = []\n",
    "# order blocks based on y axes aka paragraphcs from top to bottom\n",
    "ordered_blocks = order_blocks(blocks)\n",
    "i = 0\n",
    "# determine if blocks on one line or not and based on that assign latex tag\n",
    "while i < len(ordered_blocks):\n",
    "    if blocks[i].is_math:\n",
    "        final_blocks.append(blocks[i])\n",
    "        i = i+1\n",
    "    else:\n",
    "        x = ordered_blocks[i].bounding_box[0]\n",
    "        y = ordered_blocks[i].bounding_box[1]\n",
    "        x_end = ordered_blocks[i].bounding_box[2]\n",
    "        y_end = ordered_blocks[i].bounding_box[3]\n",
    "        end_line = False\n",
    "        index_list = []\n",
    "        while(not end_line):\n",
    "            index_list.append(i)\n",
    "            if i+1 < len(ordered_blocks): \n",
    "                x_next = ordered_blocks[i+1].bounding_box[0]\n",
    "                y_next = ordered_blocks[i+1].bounding_box[1]\n",
    "                #x_next_end = ordered_blocks[i+1].bounding_box[2]\n",
    "                #y_next_end = ordered_blocks[i+1].bounding_box[3]\n",
    "                if y_next >= y_end and y_next <= y_end+20 and x_next > x_end: # next to it# next in the same line\n",
    "                    index_list.append(i+1)\n",
    "                    i = i+1\n",
    "                else: # the next is not beside it\n",
    "                    end_line = True\n",
    "            else:\n",
    "                end_line = True\n",
    "        each_size = 1 / len(index_list) \n",
    "        for index in index_list:\n",
    "            block = ordered_blocks[index]\n",
    "            block.latex_code = \"\"\"\n",
    "            \\parbox{\"\"\"+str(each_size)+\"\"\"\\\\textwidth}{%\n",
    "                \"\"\"+block.latex_code+\"\"\"\n",
    "            }%\n",
    "            \"\"\"\n",
    "            final_blocks.append(block)\n",
    "        i = i+1\n",
    "\n",
    "#add margins to each latex block based on orig document\n",
    "for i in range(0,len(final_blocks)):\n",
    "    x = final_blocks[i].bounding_box[0]\n",
    "    y = final_blocks[i].bounding_box[1]\n",
    "    x_end = final_blocks[i].bounding_box[2]\n",
    "    y_end = final_blocks[i].bounding_box[3]\n",
    "    if i+1 < len(final_blocks): \n",
    "        x_next = final_blocks[i+1].bounding_box[0]\n",
    "        y_next = final_blocks[i+1].bounding_box[1]\n",
    "        if y_next >= y_end and y_next <= y_end+20 and x_next > x_end: # next to it\n",
    "            final_blocks[i].latex_code = final_blocks[i].latex_code+\"\\hspace{\"+str(x_next-x_end)+\"pt}\"\n",
    "        else: # not next to it\n",
    "            final_blocks[i].latex_code = final_blocks[i].latex_code+\"\\\\vspace{\"+str(y_next-y_end)+\"pt}\"\n",
    "                \n",
    "# merge blocks and create latex document\n",
    "latex_string = add_blocks_to_latex(final_blocks)\n",
    "latex_file = open(\"latex.tex\",\"w\")\n",
    "latex_file.write(latex_string)\n",
    "latex_file.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                COMBINATION OF VISION AND NLP ONE OF THE STERGTHS OF OUR ARCHITECTURE IS IN THE COMBINATION OF VISION AND LANGUAGE MODELS. CNNS SUCH AS RESNET ATE CONSIDERED BEST FOR PROCESSING IMAGE DATA. AND TRANSFORMERS ATE CONSIDERED BEST FOR LANGUAGE MODELING (LM) AND NATURAL LANGUAGE UNDERSTANDING (NLU) TASKS [7, 24, 25] POSESSING PROPERTIES THAT ATE VERY USEFUL IN DEALING WITH NOISY AND INCOMPLETE TEXT THAT OFFEN OCCURS IN REAL HANDWRITING. HAVING BOTH THE VISUAL FEATURE MAP AND A LANGUAGE MODEL, THE MODEL CAN DO A MUCH BETTER JOB THAN ONE RELYING ON VISUAL FEATURES ALONE.\n",
      "            }%\n",
      "            \\vspace{24.801514pt}\n",
      "            }%\n",
      "            \\vspace{24.801514pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                INFERENCE WE USE SIMPLE GREEDY DECODING, WHICH PICKS THE HIGHEST PROBABIL- ITY TOKEN AT EACH STEP. BEAM SEARCH DECODING [8] DID NOT YIELD ANY ACCURACY IMPROVEMENT INDICATING THAT THE MODEL IS QUITE OPINIONATED / CONFIDENT.\n",
      "            }%\n",
      "            \\vspace{58.95465pt}\n",
      "            }%\n",
      "            \\vspace{58.95465pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                THE BASE CONFIGURATION USES GRAYSCALE IMAGES SCALED DOWN TO 140-150 DOTS PER INCH. HIGHER RESOLUTIONS YIELDED SLIGHTLY BETTER ACCURACY AT THE COST OF COMPUTE AND MEMORY. WE USE THE 34-LAYER CONFIGURATION OF RESNET, BUT HAVE ALSO SUC- CESSFULLY TRAINED THE 18-LAYER AND 50-LAYER CONFIGURATIONS; LARGER MODELS TENDING TO DO BETTER IN GENERAL AS EXPECTED.\n",
      "            }%\n",
      "            \\vspace{-569.8107pt}\n",
      "            }%\n",
      "            \\vspace{-569.8107pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                AS IS TYPICAL WITH SEQUENCE GENERATORS, THE TRAINING OBJECTIVE BERE IS TO MAX- IMIZE PROBABILITY OF THE TARGET SEQUENCE GST. WE USE THE STANDARD PER-WORD CROSS-ENTROPY OBJECTIVE (EQUATION 5), MODIFIED SLIGHTLY FOR THE MIMI-BATCH (EQUA- TION 6). WE DID NOT LISE ANY REGULARIZATION OBJECTIVE, RELYING INSTEAD ON DROPOUT, DATA-AUGMENTATIONS AND SYNTHETIC DATA TO PROVIDE REGULARIZATION.\n",
      "            }%\n",
      "            \\vspace{97.96326pt}\n",
      "            }%\n",
      "            \\vspace{97.96326pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                THE FINAL LINEAR LAYER OF THE DECODER (FIGURE. 3A) IS A 1X1 CONVOLUTION FUNCTION THAT PRODUCES LOTTS WHICH ATE THEN NORMALIZED BY SOFTMAX TO PRODUCE PT-\n",
      "            }%\n",
      "            \\vspace{362.67587pt}\n",
      "            }%\n",
      "            \\vspace{362.67587pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                THE FOLLOWING IS THE BASE CONFIGURATION OF THE TRANSFORMER STACK:\n",
      "            }%\n",
      "            \\vspace{-704.2846pt}\n",
      "            }%\n",
      "            \\vspace{-704.2846pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                PROBADILITY OF THE ENTIRE TOKEN SEQUENCE IS THEREFORE GIVEN BY EQUATION 4\n",
      "            }%\n",
      "            \\vspace{559.1076pt}\n",
      "            }%\n",
      "            \\vspace{559.1076pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                TRAINING CONFIGURATION AND PROCEDURE\n",
      "            }%\n",
      "            \\vspace{122.81958pt}\n",
      "            }%\n",
      "            \\vspace{122.81958pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                N NUMBER OF LAYERS) 1 S 1\n",
      "            }%\n",
      "            \\vspace{-702.6819pt}\n",
      "            }%\n",
      "            \\vspace{-702.6819pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            }%\n",
      "            \\vspace{671.0257pt}\n",
      "            }%\n",
      "            \\vspace{671.0257pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                N NUMBER OF LAYERS) 5\n",
      "            }%\n",
      "            \\vspace{-681.2998pt}\n",
      "            }%\n",
      "            \\vspace{-681.2998pt}\n",
      "\n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            \\parbox{1.0\\textwidth}{%\n",
      "                \n",
      "            }%\n",
      "            \n",
      "            }%\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "009d393f7cff45abb740154420c54dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0304bf12259847b78d8a1285fcaaa297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "03a889da7aaa498899e0835211246c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_740844e6be084476874781dede9ccd77",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da35b496b0104b438d47a4a1d126a368",
      "value": 190
     }
    },
    "0574b821200b40a99e1626faa108e25d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "075cf95270fa45b3a3c1888451c7bffc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_703c08f902b24322b40d3b96cef400c9",
       "IPY_MODEL_5552b498397e43af9205840ce2b31e54",
       "IPY_MODEL_a3b6dd73f9d649ab8059e13518901e41"
      ],
      "layout": "IPY_MODEL_bc3eadcb8df64dda819786e8ba61be65"
     }
    },
    "0c437278d1e14472a08d8c73eed3cd6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c6612e5ac8b478886f0eadcd2619328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1119b0c17f59495999d11f59006ed224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "172aa5627a92491385a61dbdd9aa56cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "176e2e28745f4b3281b359a76ff957ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "20cd442d13f64a95b64fa66dcbfb1fcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_330fc1482ee344679b1b8f260996bb64",
       "IPY_MODEL_76dcd778515d4891811b0dfc09d5fb25",
       "IPY_MODEL_971d9d2604c44989b23523b19a648640"
      ],
      "layout": "IPY_MODEL_dd91459701d34b378789353780b83228"
     }
    },
    "28117087f3f0445ca86068922baf2160": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30ae090134a544cb86c70449232cec56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "330040e86fac46efb871483fcd0f8766": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "330fc1482ee344679b1b8f260996bb64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0d179510ca0442a9fde8cec5d460794",
      "placeholder": "​",
      "style": "IPY_MODEL_5028b32f063a4744b837723e6ea4f0c5",
      "value": "merges.txt: 100%"
     }
    },
    "36496791826c40b1a8932be191e23870": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36c42b4651284101bf09bdd844df134e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd8fd6a464254062983bdd84fe423f48",
       "IPY_MODEL_03a889da7aaa498899e0835211246c5a",
       "IPY_MODEL_55cab78ac9b3439ea764e8e23ffd6d4c"
      ],
      "layout": "IPY_MODEL_c5c1674dfdff49e7801e8d3870529e15"
     }
    },
    "3887d1dc60d34dd8a9be2a424c9f8359": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c41c8d58d04da996cbb249ab2bc616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80c588a60a4e4706834c25bb95aef8ee",
      "placeholder": "​",
      "style": "IPY_MODEL_30ae090134a544cb86c70449232cec56",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "402a7255a22441e5ba7cfda3a443a33f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9c0bbd45c2e481abfca97ea609eb123",
      "placeholder": "​",
      "style": "IPY_MODEL_fe925507eec742d9958aff635280877a",
      "value": " 2.43G/2.43G [00:27&lt;00:00, 155MB/s]"
     }
    },
    "433f691635614aa08efacdc3d563c460": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43488b959cf74c7189057ef5185c281e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "437bfa380c574ac8b2b07077a6dc15cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e227c3a291e4be2a5bd4b22f6df663d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5028b32f063a4744b837723e6ea4f0c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5130bd3b0a574f74825e41661b71cc3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dc62819b9ea4a8fa4b43906582d5cfe",
      "max": 772,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c6612e5ac8b478886f0eadcd2619328",
      "value": 772
     }
    },
    "5552b498397e43af9205840ce2b31e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de8dac42f187427192f158a0b977ebe8",
      "max": 4209,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b35ea204fa374b8cbf0614dd943c0eab",
      "value": 4209
     }
    },
    "55cab78ac9b3439ea764e8e23ffd6d4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd88b4a5dfd74060b14b47a103dae5d1",
      "placeholder": "​",
      "style": "IPY_MODEL_0304bf12259847b78d8a1285fcaaa297",
      "value": " 190/190 [00:00&lt;00:00, 8.21kB/s]"
     }
    },
    "5ec2547b9a34498ab199466b2e9835f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "632567a4c9b94b0aa908ddaa4a664d28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6492995e484c43aaab1ae4ff7c8223a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a66dac9d28314374873d9d0e9038cd3c",
      "placeholder": "​",
      "style": "IPY_MODEL_172aa5627a92491385a61dbdd9aa56cc",
      "value": " 899k/899k [00:00&lt;00:00, 9.54MB/s]"
     }
    },
    "652ebee98df9488ca3b9f7b1913c4ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39c41c8d58d04da996cbb249ab2bc616",
       "IPY_MODEL_b79c568675b24a949ed1b6175253b7a9",
       "IPY_MODEL_6bdf124bc8fd453498a8d67a4fc89310"
      ],
      "layout": "IPY_MODEL_433f691635614aa08efacdc3d563c460"
     }
    },
    "67eefa4326144c478d69236279c3c031": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2063d0335a846ad80f4f6fafb38f96d",
       "IPY_MODEL_5130bd3b0a574f74825e41661b71cc3b",
       "IPY_MODEL_8dde87f054c34e02bf3cd6e754727fec"
      ],
      "layout": "IPY_MODEL_b65b7b8b1e0e4e229ad5141558308e71"
     }
    },
    "6bdf124bc8fd453498a8d67a4fc89310": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84efd2ff0040449b9646a912bb40d965",
      "placeholder": "​",
      "style": "IPY_MODEL_e338be98e5794c40b09285572f12d99e",
      "value": " 228/228 [00:00&lt;00:00, 4.35kB/s]"
     }
    },
    "703c08f902b24322b40d3b96cef400c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c437278d1e14472a08d8c73eed3cd6b",
      "placeholder": "​",
      "style": "IPY_MODEL_e7cbad4d7273456b8190a8f2688d9855",
      "value": "config.json: 100%"
     }
    },
    "70d743acdc2c46318dcbacd2a6d1fa7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "740844e6be084476874781dede9ccd77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7563d5b1906a496694502291baf73f1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76d6c2a888424b479f8269e35495410a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28117087f3f0445ca86068922baf2160",
      "placeholder": "​",
      "style": "IPY_MODEL_632567a4c9b94b0aa908ddaa4a664d28",
      "value": "model.safetensors: 100%"
     }
    },
    "76dcd778515d4891811b0dfc09d5fb25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b64c52d0e98946d7a285b5d84da63022",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_176e2e28745f4b3281b359a76ff957ad",
      "value": 456318
     }
    },
    "7b717746e3634465bf4872fee23e21b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "804963e6d38e42918433ef27f99ac43a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70d743acdc2c46318dcbacd2a6d1fa7f",
      "max": 2432558500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b717746e3634465bf4872fee23e21b4",
      "value": 2432558500
     }
    },
    "80c588a60a4e4706834c25bb95aef8ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "836d7f58e3c14b3d99923dbf789a6085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_892ab7092d404b3cbbff79ff259bfeeb",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7b2175d277b4e4083f638224c533e3a",
      "value": 898822
     }
    },
    "84efd2ff0040449b9646a912bb40d965": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f391dfd43141bd8d287c04503b78cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7d061f61b6b4500979b4740f0f6f394",
       "IPY_MODEL_836d7f58e3c14b3d99923dbf789a6085",
       "IPY_MODEL_6492995e484c43aaab1ae4ff7c8223a5"
      ],
      "layout": "IPY_MODEL_a2073c8177774d6fb9fa9fd0f74cc010"
     }
    },
    "86033af5cca44af4bbd7ab463a36c915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76d6c2a888424b479f8269e35495410a",
       "IPY_MODEL_804963e6d38e42918433ef27f99ac43a",
       "IPY_MODEL_402a7255a22441e5ba7cfda3a443a33f"
      ],
      "layout": "IPY_MODEL_b0be0cec969e4eaa872df6e1ab0388fd"
     }
    },
    "8901540fbbc7460ca7de5ac729d48554": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "892ab7092d404b3cbbff79ff259bfeeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dde87f054c34e02bf3cd6e754727fec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f31a88dd23343bca27a724d01f39993",
      "placeholder": "​",
      "style": "IPY_MODEL_43488b959cf74c7189057ef5185c281e",
      "value": " 772/772 [00:00&lt;00:00, 13.0kB/s]"
     }
    },
    "8e97e890f19a4f81ad328991c0a30246": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971d9d2604c44989b23523b19a648640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_437bfa380c574ac8b2b07077a6dc15cf",
      "placeholder": "​",
      "style": "IPY_MODEL_a684f852e6a342f98ea5959bb38ba517",
      "value": " 456k/456k [00:00&lt;00:00, 1.15MB/s]"
     }
    },
    "9d9250c9668048df915f504f19b2a477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dc62819b9ea4a8fa4b43906582d5cfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f31a88dd23343bca27a724d01f39993": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f456a6df57544daa8a8b6f9bdbd5ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7563d5b1906a496694502291baf73f1c",
      "placeholder": "​",
      "style": "IPY_MODEL_1119b0c17f59495999d11f59006ed224",
      "value": " 1.12k/1.12k [00:00&lt;00:00, 15.2kB/s]"
     }
    },
    "a2073c8177774d6fb9fa9fd0f74cc010": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2cde8e2dc794e7f8c522de9afac5798": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbb4a2e8f21b454e89e99d41bba03b28",
       "IPY_MODEL_e890b10aab2f4ffa87f01e076a745342",
       "IPY_MODEL_9f456a6df57544daa8a8b6f9bdbd5ec1"
      ],
      "layout": "IPY_MODEL_330040e86fac46efb871483fcd0f8766"
     }
    },
    "a3b6dd73f9d649ab8059e13518901e41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e97e890f19a4f81ad328991c0a30246",
      "placeholder": "​",
      "style": "IPY_MODEL_4e227c3a291e4be2a5bd4b22f6df663d",
      "value": " 4.21k/4.21k [00:00&lt;00:00, 106kB/s]"
     }
    },
    "a66dac9d28314374873d9d0e9038cd3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a684f852e6a342f98ea5959bb38ba517": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0be0cec969e4eaa872df6e1ab0388fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0d179510ca0442a9fde8cec5d460794": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b35ea204fa374b8cbf0614dd943c0eab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b64c52d0e98946d7a285b5d84da63022": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b65b7b8b1e0e4e229ad5141558308e71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b79c568675b24a949ed1b6175253b7a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e68cc00f6a71477e83f2e45a3b7b8542",
      "max": 228,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb203359267040f883d3603cfc427807",
      "value": 228
     }
    },
    "bbb4a2e8f21b454e89e99d41bba03b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36496791826c40b1a8932be191e23870",
      "placeholder": "​",
      "style": "IPY_MODEL_9d9250c9668048df915f504f19b2a477",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "bc3eadcb8df64dda819786e8ba61be65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd88b4a5dfd74060b14b47a103dae5d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3e064f78bb14fc0bab851cb6817163b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5c1674dfdff49e7801e8d3870529e15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9c0bbd45c2e481abfca97ea609eb123": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2063d0335a846ad80f4f6fafb38f96d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3887d1dc60d34dd8a9be2a424c9f8359",
      "placeholder": "​",
      "style": "IPY_MODEL_dea56691ca534be0a0996f37e5a1edbe",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "d7d061f61b6b4500979b4740f0f6f394": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8901540fbbc7460ca7de5ac729d48554",
      "placeholder": "​",
      "style": "IPY_MODEL_c3e064f78bb14fc0bab851cb6817163b",
      "value": "vocab.json: 100%"
     }
    },
    "da35b496b0104b438d47a4a1d126a368": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd91459701d34b378789353780b83228": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de8dac42f187427192f158a0b977ebe8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea56691ca534be0a0996f37e5a1edbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e338be98e5794c40b09285572f12d99e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e68cc00f6a71477e83f2e45a3b7b8542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7b2175d277b4e4083f638224c533e3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7cbad4d7273456b8190a8f2688d9855": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e890b10aab2f4ffa87f01e076a745342": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f84a7fb0f97e4ec98c7bb10de62c789f",
      "max": 1118,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ec2547b9a34498ab199466b2e9835f8",
      "value": 1118
     }
    },
    "f84a7fb0f97e4ec98c7bb10de62c789f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb203359267040f883d3603cfc427807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd8fd6a464254062983bdd84fe423f48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0574b821200b40a99e1626faa108e25d",
      "placeholder": "​",
      "style": "IPY_MODEL_009d393f7cff45abb740154420c54dde",
      "value": "generation_config.json: 100%"
     }
    },
    "fe925507eec742d9958aff635280877a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
