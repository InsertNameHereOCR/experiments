{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas numpy transformers matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yNF1MXAgGuk",
        "outputId": "efd0b3a7-44c5-4673-b367-2e1f0669f518"
      },
      "outputs": [],
      "source": [
        "!git clone https://huggingface.co/microsoft/trocr-large-handwritten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS1kgVlMgGul",
        "outputId": "0e184480-c9c9-4f79-de63-ecc583cb49bd"
      },
      "outputs": [],
      "source": [
        "#wget csak linuxon műkszik\n",
        "!wget \"https://huggingface.co/datasets/zhixiaoni/CROHME_selected_Train_2014_png/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDy6EsosgGul"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bBsUj9egGum",
        "outputId": "802b087e-748b-4400-f94e-649baa038e8d"
      },
      "outputs": [],
      "source": [
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
        "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')\n",
        "i_list = [0]\n",
        "\n",
        "def OCR(row,i_list,processor,model):\n",
        "    i_list[0]= i_list[0]+1\n",
        "    print(i_list[0])\n",
        "    nparr = np.fromstring(row[\"image\"][\"bytes\"], np.uint8)\n",
        "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "    #plt.figure(figsize=(10,10)); plt.axis('off'); plt.imshow(img)\n",
        "    #plt.show()\n",
        "    pixel_values = processor(images=img, return_tensors=\"pt\").pixel_values\n",
        "    generated_ids = model.generate(pixel_values)\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    print(generated_text)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Vq1g7fiwgGum",
        "outputId": "2eecec28-1a58-4b1b-a963-a494ba44ff00"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(\"./0000.parquet\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8bQ4IYygGum",
        "outputId": "7b1ffe83-fc5d-4738-c048-157b219fa345"
      },
      "outputs": [],
      "source": [
        "df = df.head(3000)\n",
        "df[\"text\"] = df.apply(lambda x: OCR(x, i_list,processor,model), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFebkqYXgGum",
        "outputId": "79f637a2-0b44-4772-c53d-ffb2c79f5d0e"
      },
      "outputs": [],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFH5aZyjgGum"
      },
      "outputs": [],
      "source": [
        "df.to_csv('ocr_results_3000.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"ocr_results_3000.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoEs71WugGum"
      },
      "outputs": [],
      "source": [
        "def big_num_as_str(number):\n",
        "    return \"{:,}\".format(number)\n",
        "\n",
        "def get_patterns(ocr_results=['alma', 'korte', 'balma', 'almkortelma'], pattern_len=3):\n",
        "    patterns = []\n",
        "    for res in ocr_results:\n",
        "        word_len = len(res)\n",
        "        start_index = 0\n",
        "        print(f\"checking patterns with: {res}\")\n",
        "        for i in range(0, word_len-1):\n",
        "            end_index = i+pattern_len\n",
        "            possible_pattern = res[start_index : end_index]\n",
        "            if (len(possible_pattern) != pattern_len):\n",
        "                break\n",
        "            print(f\"\\tpossible_patter: {possible_pattern}, indexes: {start_index}:{end_index}\")\n",
        "\n",
        "            #compare with other results\n",
        "            for other_result in ocr_results:\n",
        "                if (possible_pattern in other_result and other_result != res):\n",
        "                    patterns.append(possible_pattern)\n",
        "            start_index += 1\n",
        "        print()\n",
        "    print(f\"results: {patterns}\")\n",
        "    return patterns\n",
        "\n",
        "def filter_patterns(patterns, min_occurance=3):\n",
        "    pattern_ocs = []\n",
        "    values = {}\n",
        "    temp_arr = []\n",
        "    index = 0\n",
        "\n",
        "    for pattern in patterns:\n",
        "        print(f\"index: {big_num_as_str(index)}, from : {big_num_as_str(len(patterns))}\")\n",
        "        index += 1\n",
        "        if (pattern not in temp_arr):\n",
        "            temp_arr.append(pattern)\n",
        "            counter = -1\n",
        "            for other in patterns:\n",
        "                if (other == pattern):\n",
        "                    counter += 1\n",
        "            if (counter >= min_occurance):\n",
        "                print(f'new pattern found: {pattern} - occurences: {counter}')\n",
        "                values = {}\n",
        "                values[\"pattern\"] = pattern\n",
        "                values[\"counter\"] = counter\n",
        "                pattern_ocs.append(values)\n",
        "    return pattern_ocs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJMgNKuwgGun"
      },
      "outputs": [],
      "source": [
        "possible_patterns_3 = get_patterns(ocr_results=df['text'].to_list(), pattern_len=3)\n",
        "possible_patterns_4 = get_patterns(ocr_results=df['text'].to_list(), pattern_len=4)\n",
        "possible_patterns_5 = get_patterns(ocr_results=df['text'].to_list(), pattern_len=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "possible_patterns_3.extend(possible_patterns_4)\n",
        "possible_patterns_3.extend(possible_patterns_5)\n",
        "possible_patterns = possible_patterns_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNuyInG8gGun",
        "outputId": "2c4214b3-8553-4a76-ddb2-1a81d868ba58"
      },
      "outputs": [],
      "source": [
        "patterns = filter_patterns(patterns=possible_patterns, min_occurance=5)\n",
        "#print(patterns)\n",
        "pattern_df = pd.DataFrame.from_records(patterns)\n",
        "pattern_df = pattern_df.drop_duplicates()\n",
        "pattern_df.to_csv(\"patterns.csv\", index=False)\n",
        "\n",
        "pattern_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pattern_df = pd.read_csv(\"patterns.csv\")\n",
        "pattern_df = pattern_df.sort_values(by=[\"counter\"], ascending=False)\n",
        "pattern_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PATTERNEK-BŐL KI KELLENE SZŰRNI AZ ANGOL SZAVAKAT\n",
        "import json\n",
        "\n",
        "en_dict = json.load(open(\"words_dictionary.json\"))\n",
        "wrong_indexes = []\n",
        "\n",
        "for index, row in pattern_df.iterrows():\n",
        "    el = row['pattern']\n",
        "    if el in en_dict:\n",
        "        wrong_indexes.append(index)\n",
        "        #print(f'found this: {el} on index {index}')\n",
        "    elif el.replace(\" \", \"\") in en_dict:\n",
        "        wrong_indexes.append(index)\n",
        "\n",
        "print(pattern_df.count)\n",
        "pattern_df.drop(wrong_indexes,axis=0,inplace=True)\n",
        "print(pattern_df.count)\n",
        "\n",
        "pattern_df.to_csv(\"patterns_no_word.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#img = cv2.imread(\"test_imgs/mixed_test_2.png\") # fail probably text\n",
        "#img = cv2.imread(\"test_imgs/mixed_test_3.png\") # fail probably text\n",
        "#img = cv2.imread(\"test_imgs/mixed_test_4.png\") # fail math\n",
        "#img = cv2.imread(\"test_imgs/mixed_test_5.png\") # fail math\n",
        "#img = cv2.imread(\"test_imgs/mixed_test_6.png\") # fail probably text\n",
        "#img = cv2.imread(\"test_imgs/math_test_8.png\") # fail probably text\n",
        "#img = cv2.imread(\"test_imgs/math_test_13.png\") # fail probably text\n",
        "# img = cv2.imread(\"test_imgs/text_test_7.png\")  #fail probably text\n",
        "#img = cv2.imread(\"test_imgs/math_test_16.png\") #fail probably text\n",
        "#img = cv2.imread(\"test_imgs/math_test_18.png\") #fail probably text\n",
        "#img = cv2.imread(\"test_imgs/math_test_19.png\") #fail probably text\n",
        "#img = cv2.imread(\"test_imgs/math_test_19.png\")\n",
        "\n",
        "#img = cv2.imread(\"test_imgs/math_test_4.png\") #ok\n",
        "#img = cv2.imread(\"test_imgs/math_test_5.png\") #ok\n",
        "#img = cv2.imread(\"test_imgs/math_test_6.png\") # ok\n",
        "#img = cv2.imread(\"test_imgs/math_test_7.png\") #ok\n",
        "#img = cv2.imread(\"test_imgs/math_test_8.png\") #elég edge case, ezt adja az ocr: 'Sebards #'\n",
        "\n",
        "img = cv2.imread(\"test_imgs/text_test_8.png\")\n",
        "#img = cv2.imread(\"test_imgs/text_test_easy.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
        "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_values = processor(images=img, return_tensors=\"pt\").pixel_values\n",
        "generated_ids = model.generate(pixel_values)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_distances(found_patterns, text, max_char_distance):\n",
        "    #megnézi, h van-e legalább egy olyan pattern ami elég közel van hozzá\n",
        "    num_of_close = 0\n",
        "    close_pairs = []\n",
        "    for i in range(len(found_patterns)):\n",
        "        for j in range(len(found_patterns)):\n",
        "            if j > i:\n",
        "                char_distance = abs(text.find(found_patterns[i]) - text.find(found_patterns[j]))\n",
        "                if max_char_distance >= char_distance and char_distance > 1:\n",
        "                    close_pairs.append([found_patterns[i], found_patterns[j]])\n",
        "                    num_of_close = num_of_close+1\n",
        "                    break\n",
        "    '''for pair in close_pairs:\n",
        "        print(pair)'''\n",
        "    return num_of_close\n",
        "\n",
        "def check_patterns_in_string(text, cutoff =.45 ,max_char_distance=5, do_prints=True, csv_to_read_from='patterns_no_word.csv'):\n",
        "    pattern_df = pd.read_csv(csv_to_read_from)\n",
        "    patterns_as_list = pattern_df['pattern'].to_list()\n",
        "    if do_prints == True: print(f\"Checking patterns in '{text}'\")\n",
        "    \n",
        "    found_patterns = []\n",
        "    pattern_len = len(patterns_as_list[0])\n",
        "    text_len = len(text)\n",
        "    possible_pattern_count = text_len-pattern_len+1\n",
        "    if do_prints == True: print(f\"text_len: {text_len}, possible_pattern_count: {possible_pattern_count}\")    \n",
        "\n",
        "    #if do_prints == True: print(patterns_as_list)\n",
        "    for pattern in patterns_as_list:\n",
        "        if (pattern in text):\n",
        "            found_patterns.append(pattern)\n",
        "\n",
        "    if do_prints == True: print(f\"\\nfound {len(found_patterns)} patterns in the text\")\n",
        "    if do_prints == True: print(found_patterns)\n",
        "    \n",
        "    if (round(possible_pattern_count * cutoff) <= len(found_patterns)):\n",
        "        # check distance of words\n",
        "        min_num_of_close = len(found_patterns) * .75\n",
        "        num_of_close = check_distances(found_patterns, text, max_char_distance)\n",
        "\n",
        "        print(f'num_of_close: {num_of_close}, min: {len(found_patterns)}*.75={min_num_of_close}')\n",
        "        if num_of_close >= min_num_of_close:\n",
        "            if do_prints == True: print(\"math\")\n",
        "            return 'math'            \n",
        "        else:\n",
        "            if do_prints == True: print(\"mixed\")\n",
        "            return 'mixed'\n",
        "\n",
        "    elif (round(possible_pattern_count * cutoff) > len(found_patterns)):\n",
        "        if do_prints == True: print('probably text')\n",
        "        return 'probably text'\n",
        "    else:\n",
        "        if do_prints == True: print('pretty sure its text')\n",
        "        return 'pretty sure its text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "check_patterns_in_string(generated_text, cutoff=.45, do_prints=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def test_pattern_check(img_type='math_test', correct_results=['math'], csv_to_read_patterns_from='patterns_no_word.csv', print_inner_logs=True):\n",
        "    counter = 1\n",
        "    tests_good = []\n",
        "    tests_bad = []\n",
        "    num_of_imgs = 0\n",
        "    img_paths = []\n",
        "    for subdir, dirs, files in os.walk('test_imgs'):\n",
        "        for file in files:\n",
        "            #print os.path.join(subdir, file)\n",
        "            filepath = subdir + os.sep + file\n",
        "            if img_type in filepath: \n",
        "                num_of_imgs += 1\n",
        "                img_paths.append(filepath)\n",
        "    print(img_paths)\n",
        "    print(num_of_imgs)\n",
        "    for img_path in img_paths:\n",
        "        img = cv2.imread(img_path)\n",
        "        #ocr\n",
        "        pixel_values = processor(images=img, return_tensors=\"pt\").pixel_values\n",
        "        generated_ids = model.generate(pixel_values)\n",
        "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "        print(f'generated this string: \"{generated_text}\" from img {img_path}')\n",
        "        #checking patterns\n",
        "        result = check_patterns_in_string(generated_text, cutoff=.45, do_prints=print_inner_logs, csv_to_read_from=csv_to_read_patterns_from)\n",
        "        print(result)\n",
        "        if result in correct_results:\n",
        "            tests_good.append(True)\n",
        "        else:\n",
        "            tests_bad.append(False)\n",
        "        print(f'processed: {counter}/{num_of_imgs}\\n')\n",
        "        counter += 1\n",
        "    print(f'Successrate = {(len(tests_good)/(len(tests_good)+len(tests_bad)))*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_pattern_check(img_type='math_test', correct_results=['math'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_pattern_check(img_type='mixed_test', correct_results=['mixed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_pattern_check(img_type='text_test', correct_results=['pretty sure its text', 'probably text'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
