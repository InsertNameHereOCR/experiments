{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub dghs-imgutils hbutils>=0.9.1 opencv-python numpy pillow pandas transformers matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'trocr-large-handwritten'...\n",
      "remote: Enumerating objects: 33, done.\u001b[K\n",
      "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 33 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (33/33), 540.03 KiB | 1.64 MiB/s, done.\n",
      "fatal: active `post-checkout` hook found during `git clone`:\n",
      "\t/home/akos/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/trocr-large-handwritten/.git/hooks/post-checkout\n",
      "For security reasons, this is disallowed by default.\n",
      "If this is intentional and the hook should actually be run, please\n",
      "run the command again with `GIT_CLONE_PROTECTION_ACTIVE=false`\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/microsoft/trocr-large-handwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
      "Collecting torchvision==0.10.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.7.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
      "Requirement already satisfied: pillow>=5.3.0 in ./.venv/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (9.5.0)\n",
      "Using cached torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==1.5.10 (from -r requirements.txt (line 1))\n",
      "  Using cached pytorch_lightning-1.5.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting torchmetrics==0.6.0 (from -r requirements.txt (line 2))\n",
      "  Using cached torchmetrics-0.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting einops==0.3.0 (from -r requirements.txt (line 3))\n",
      "  Using cached einops-0.3.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting editdistance==0.5.3 (from -r requirements.txt (line 4))\n",
      "  Using cached editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl.metadata (473 bytes)\n",
      "Collecting jsonargparse==3.9.0 (from jsonargparse[signatures]==3.9.0->-r requirements.txt (line 6))\n",
      "  Using cached jsonargparse-3.9.0-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting flake8==3.9.0 (from -r requirements.txt (line 8))\n",
      "  Using cached flake8-3.9.0-py2.py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting black==20.8b1 (from -r requirements.txt (line 9))\n",
      "  Using cached black-20.8b1-py3-none-any.whl\n",
      "Collecting isort==5.8.0 (from -r requirements.txt (line 10))\n",
      "  Using cached isort-5.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jupyter==1.0.0 (from -r requirements.txt (line 11))\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (9.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in ./.venv/lib/python3.7/site-packages (from pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (1.21.6)\n",
      "Requirement already satisfied: torch>=1.7.* in ./.venv/lib/python3.7/site-packages (from pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (1.9.0+cu111)\n",
      "Collecting future>=0.17.1 (from pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in ./.venv/lib/python3.7/site-packages (from pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.1 in ./.venv/lib/python3.7/site-packages (from pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in ./.venv/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (2023.1.0)\n",
      "Collecting tensorboard>=2.2.0 (from pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pyDeprecate==0.3.1 (from pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached pyDeprecate-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.7/site-packages (from pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.7/site-packages (from pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (4.7.1)\n",
      "Collecting setuptools==59.5.0 (from pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached setuptools-59.5.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyflakes<2.4.0,>=2.3.0 (from flake8==3.9.0->-r requirements.txt (line 8))\n",
      "  Using cached pyflakes-2.3.1-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pycodestyle<2.8.0,>=2.7.0 (from flake8==3.9.0->-r requirements.txt (line 8))\n",
      "  Using cached pycodestyle-2.7.0-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0 (from flake8==3.9.0->-r requirements.txt (line 8))\n",
      "  Using cached mccabe-0.6.1-py2.py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.7/site-packages (from flake8==3.9.0->-r requirements.txt (line 8)) (6.7.0)\n",
      "Collecting click>=7.1.2 (from black==20.8b1->-r requirements.txt (line 9))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting appdirs (from black==20.8b1->-r requirements.txt (line 9))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting toml>=0.10.1 (from black==20.8b1->-r requirements.txt (line 9))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typed-ast>=1.4.0 (from black==20.8b1->-r requirements.txt (line 9))\n",
      "  Using cached typed_ast-1.5.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: regex>=2020.1.8 in ./.venv/lib/python3.7/site-packages (from black==20.8b1->-r requirements.txt (line 9)) (2024.4.16)\n",
      "Collecting pathspec<1,>=0.6 (from black==20.8b1->-r requirements.txt (line 9))\n",
      "  Using cached pathspec-0.11.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black==20.8b1->-r requirements.txt (line 9))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting notebook (from jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Downloading notebook-6.5.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting qtconsole (from jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached qtconsole-5.4.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting jupyter-console (from jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached nbconvert-7.6.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 11)) (6.16.2)\n",
      "Collecting ipywidgets (from jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting docstring-parser>=0.7.3 (from jsonargparse[signatures]==3.9.0->-r requirements.txt (line 6))\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (2.31.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached aiohttp-3.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.24.3 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached grpcio-1.62.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting protobuf<4,>=3.9.2 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached Werkzeug-2.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting wheel>=0.26 (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.7/site-packages (from importlib-metadata->flake8==3.9.0->-r requirements.txt (line 8)) (3.15.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (1.7.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (7.34.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (7.4.9)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=17 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (6.2)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in ./.venv/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (5.9.0)\n",
      "Collecting comm>=0.1.3 (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached comm-0.1.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.7/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 11)) (4.12.0)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in ./.venv/lib/python3.7/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 11)) (3.0.43)\n",
      "Requirement already satisfied: pygments in ./.venv/lib/python3.7/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 11)) (2.17.2)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached bleach-6.0.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jinja2>=3.0 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting markupsafe>=2.0 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached nbclient-0.7.4-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached nbformat-5.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting argon2-cffi (from notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting ipython-genutils (from notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
      "Collecting Send2Trash>=1.8.0 (from notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached terminado-0.17.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting prometheus-client (from notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached prometheus_client-0.17.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting nbclassic>=0.4.7 (from notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached nbclassic-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.venv/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (3.3.2)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached multidict-6.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached yarl-1.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting asynctest==0.13.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached asynctest-0.13.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.7/site-packages (from bleach!=5.0.0->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11)) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (0.19.1)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (0.7.5)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (4.9.0)\n",
      "Requirement already satisfied: entrypoints in ./.venv/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Collecting jupyter-server>=1.8 (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached jupyter_server-1.24.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting notebook-shim>=0.2.3 (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting fastjsonschema (from nbformat>=5.7->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.7->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached jsonschema-4.17.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.7/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 11)) (0.2.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: ptyprocess in ./.venv/lib/python3.7/site-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->-r requirements.txt (line 11)) (0.7.0)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached soupsieve-2.4.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 11)) (0.8.4)\n",
      "Collecting importlib-resources>=1.4.0 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pkgutil-resolve-name>=1.3.10 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached pyrsistent-0.19.3-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anyio<4,>=3.1.0 (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached websocket_client-1.6.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.5.10->-r requirements.txt (line 1))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 11))\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
      "Using cached torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "Using cached einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Using cached editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "Using cached jsonargparse-3.9.0-py3-none-any.whl (91 kB)\n",
      "Using cached flake8-3.9.0-py2.py3-none-any.whl (73 kB)\n",
      "Using cached isort-5.8.0-py3-none-any.whl (103 kB)\n",
      "Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
      "Using cached pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached typed_ast-1.5.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (778 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached nbconvert-7.6.0-py3-none-any.whl (290 kB)\n",
      "Downloading notebook-6.5.7-py3-none-any.whl (529 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.8/529.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached qtconsole-5.4.4-py3-none-any.whl (121 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached aiohttp-3.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (987 kB)\n",
      "Using cached asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Using cached bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "Using cached comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Using cached grpcio-1.62.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Using cached nbclassic-1.0.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached nbclient-0.7.4-py3-none-any.whl (73 kB)\n",
      "Using cached nbformat-5.8.0-py3-none-any.whl (77 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Using cached QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Using cached terminado-0.17.1-py3-none-any.whl (17 kB)\n",
      "Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Using cached widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Using cached prometheus_client-0.17.1-py3-none-any.whl (60 kB)\n",
      "Using cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "Using cached jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "Using cached jupyter_server-1.24.0-py3-none-any.whl (347 kB)\n",
      "Using cached multidict-6.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached yarl-1.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (289 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Using cached fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Using cached cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Using cached pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "Using cached websocket_client-1.6.1-py3-none-any.whl (56 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: webencodings, tensorboard-plugin-wit, mccabe, ipython-genutils, fastjsonschema, einops, editdistance, appdirs, widgetsnbextension, wheel, websocket-client, typed-ast, toml, tinycss2, terminado, tensorboard-data-server, soupsieve, sniffio, setuptools, Send2Trash, qtpy, pyrsistent, pyflakes, pyDeprecate, pycparser, pycodestyle, pyasn1, protobuf, prometheus-client, pkgutil-resolve-name, pathspec, pandocfilters, oauthlib, mypy-extensions, multidict, mistune, markupsafe, jupyterlab-widgets, jupyterlab-pygments, jsonargparse, isort, importlib-resources, grpcio, future, frozenlist, exceptiongroup, docstring-parser, defusedxml, comm, cachetools, bleach, asynctest, async-timeout, absl-py, yarl, werkzeug, torchmetrics, rsa, requests-oauthlib, pyasn1-modules, markdown, jinja2, flake8, click, cffi, beautifulsoup4, attrs, anyio, aiosignal, jsonschema, ipywidgets, google-auth, black, argon2-cffi-bindings, aiohttp, qtconsole, nbformat, jupyter-console, google-auth-oauthlib, argon2-cffi, tensorboard, nbclient, pytorch-lightning, nbconvert, jupyter-server, notebook-shim, nbclassic, notebook, jupyter\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 68.0.0\n",
      "    Uninstalling setuptools-68.0.0:\n",
      "      Successfully uninstalled setuptools-68.0.0\n",
      "Successfully installed Send2Trash-1.8.3 absl-py-2.1.0 aiohttp-3.8.6 aiosignal-1.3.1 anyio-3.7.1 appdirs-1.4.4 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 async-timeout-4.0.3 asynctest-0.13.0 attrs-23.2.0 beautifulsoup4-4.12.3 black-20.8b1 bleach-6.0.0 cachetools-5.3.3 cffi-1.15.1 click-8.1.7 comm-0.1.4 defusedxml-0.7.1 docstring-parser-0.16 editdistance-0.5.3 einops-0.3.0 exceptiongroup-1.2.1 fastjsonschema-2.19.1 flake8-3.9.0 frozenlist-1.3.3 future-1.0.0 google-auth-2.29.0 google-auth-oauthlib-0.4.6 grpcio-1.62.2 importlib-resources-5.12.0 ipython-genutils-0.2.0 ipywidgets-8.1.2 isort-5.8.0 jinja2-3.1.4 jsonargparse-3.9.0 jsonschema-4.17.3 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-server-1.24.0 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.10 markdown-3.4.4 markupsafe-2.1.5 mccabe-0.6.1 mistune-3.0.2 multidict-6.0.5 mypy-extensions-1.0.0 nbclassic-1.0.0 nbclient-0.7.4 nbconvert-7.6.0 nbformat-5.8.0 notebook-6.5.7 notebook-shim-0.2.4 oauthlib-3.2.2 pandocfilters-1.5.1 pathspec-0.11.2 pkgutil-resolve-name-1.3.10 prometheus-client-0.17.1 protobuf-3.20.3 pyDeprecate-0.3.1 pyasn1-0.5.1 pyasn1-modules-0.3.0 pycodestyle-2.7.0 pycparser-2.21 pyflakes-2.3.1 pyrsistent-0.19.3 pytorch-lightning-1.5.10 qtconsole-5.4.4 qtpy-2.4.1 requests-oauthlib-2.0.0 rsa-4.9 setuptools-59.5.0 sniffio-1.3.1 soupsieve-2.4.1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 terminado-0.17.1 tinycss2-1.2.1 toml-0.10.2 torchmetrics-0.6.0 typed-ast-1.5.5 webencodings-0.5.1 websocket-client-1.6.1 werkzeug-2.2.3 wheel-0.42.0 widgetsnbextension-4.0.10 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'BTTR' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Green-Wood/BTTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "input_file_name = \"written.jpg\"\n",
    "image = PIL.Image.open(input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line segmention\n",
    "- from https://huggingface.co/spaces/deepghs/text_detection/blob/main/detect.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from functools import lru_cache\n",
    "from typing import List, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from huggingface_hub import HfApi, HfFileSystem, hf_hub_download\n",
    "from imgutils.data import ImageTyping\n",
    "from imgutils.utils import open_onnx_model\n",
    "from imgutils.detect import detection_visualize\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "hf_client = HfApi()\n",
    "hf_fs = HfFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def _get_onnx_session(model):\n",
    "    return open_onnx_model(hf_hub_download(\n",
    "        'deepghs/text_detection',\n",
    "        f'{model}/end2end.onnx'\n",
    "    ))\n",
    "\n",
    "def _get_heatmap_of_text(image: ImageTyping, model: str) -> np.ndarray:\n",
    "    origin_width, origin_height = width, height = image.size\n",
    "    align = 32\n",
    "    if width % align != 0:\n",
    "        width += (align - width % align)\n",
    "    if height % align != 0:\n",
    "        height += (align - height % align)\n",
    "\n",
    "    input_ = np.array(image).transpose((2, 0, 1)).astype(np.float32) / 255.0\n",
    "    # noinspection PyTypeChecker\n",
    "    input_ = np.pad(input_[None, ...], ((0, 0), (0, 0), (0, height - origin_height), (0, width - origin_width)))\n",
    "\n",
    "    def _normalize(data, mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)):\n",
    "        mean, std = np.asarray(mean), np.asarray(std)\n",
    "        return (data - mean[None, :, None, None]) / std[None, :, None, None]\n",
    "\n",
    "    ort = _get_onnx_session(model)\n",
    "\n",
    "    input_ = _normalize(input_).astype(np.float32)\n",
    "    output_, = ort.run(['output'], {'input': input_})\n",
    "    heatmap = output_[0]\n",
    "    heatmap = heatmap[:origin_height, :origin_width]\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def _get_bounding_box_of_text(image: ImageTyping, model: str, threshold: float) \\\n",
    "        -> List[Tuple[Tuple[int, int, int, int], float]]:\n",
    "    heatmap = _get_heatmap_of_text(image, model)\n",
    "    c_rets = cv2.findContours((heatmap * 255.0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = c_rets[0] if len(c_rets) == 2 else c_rets[1]\n",
    "    bboxes = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        x0, y0, x1, y1 = x, y, x + w, y + h\n",
    "        score = heatmap[y0:y1, x0:x1].mean().item()\n",
    "        if score >= threshold:\n",
    "            bboxes.append(((x0, y0, x1, y1), score))\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "def detect_text(image: ImageTyping, model: str = \"_DEFAULT_MODEL\", threshold: float = 0.05, padding: int=1):\n",
    "    bboxes = []\n",
    "    for (x0, y0, x1, y1), score in _get_bounding_box_of_text(image, model, threshold):\n",
    "        x0 = x0-padding\n",
    "        y0 = y0-padding\n",
    "        x1 = x1+padding\n",
    "        y1 = y1+padding\n",
    "        bboxes.append(((x0, y0, x1, y1), 'text', score))\n",
    "    return bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"dbnet_resnet18_fpnc_1200e_totaltext\"\n",
    "threshold = 0.1 #detection treshold\n",
    "padding = 5 # make bounding box bigger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def merge_boxes_horizontally(bboxes, threshold):\n",
    "    \"\"\"\n",
    "    Merge bounding boxes that are very close to each other horizontally.\n",
    "\n",
    "    Args:\n",
    "    bboxes (list of tuples): List of bounding boxes, each represented as (x1, y1, x2, y2).\n",
    "    threshold (int): The maximum horizontal distance between boxes to be merged.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: The modified list of bounding boxes.\n",
    "    \"\"\"\n",
    "    if not bboxes:\n",
    "        return []\n",
    "\n",
    "    # Sort the bounding boxes by the x-coordinate (x1)\n",
    "    bboxes.sort(key=lambda box: box[0])\n",
    "\n",
    "    merged_bboxes = []\n",
    "    current_box = bboxes[0]\n",
    "\n",
    "    for box in bboxes[1:]:\n",
    "        # Check if the current box and the next box are close horizontally\n",
    "        if box[0] - current_box[2] <= threshold:\n",
    "            # Merge the boxes by expanding the current box\n",
    "            current_box = (\n",
    "                current_box[0],\n",
    "                min(current_box[1], box[1]),\n",
    "                max(current_box[2], box[2]),\n",
    "                max(current_box[3], box[3])\n",
    "            )\n",
    "        else:\n",
    "            # If not close, add the current box to the merged list and move to the next box\n",
    "            merged_bboxes.append(current_box)\n",
    "            current_box = box\n",
    "\n",
    "    # Add the last box\n",
    "    merged_bboxes.append(current_box)\n",
    "\n",
    "    return merged_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "   \n",
    "    image = cv2.imread(image_path,cv2.IMREAD_COLOR)    \n",
    "    \n",
    "    cv2.imwrite(f\"binarized.png\", binarize_image(image))\n",
    "\n",
    "    return binarize_image(image)\n",
    "\n",
    "\n",
    "def binarize_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    color = [255,0,238]\n",
    "  \n",
    "    height, width, _ = image.shape\n",
    "\n",
    "\n",
    "    #binary_image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    binary_image = np.all(image == color, axis=-1) * 255\n",
    "    binary_image = 255 - binary_image\n",
    "\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "\n",
    "def find_text_lines(image):   \n",
    "    lines = []   \n",
    "    height, width = image.shape\n",
    "    for y in range(height):\n",
    "        row = image[y, :]        \n",
    "        if np.any(row == 0):\n",
    "            lines.append(1)         \n",
    "        else:\n",
    "            lines.append(0)  \n",
    "    return lines\n",
    "\n",
    "\n",
    "def extract_text_regions(original_image, lines):\n",
    "    images = []\n",
    "    start_idx = 0\n",
    "    idx = 0\n",
    "    while idx < len(lines)-1:\n",
    "        while idx < len(lines) and lines[idx] == 0:\n",
    "            idx += 1\n",
    "        if idx < len(lines) and lines[idx] == 1:\n",
    "            start_idx = idx\n",
    "        while idx < len(lines) and lines[idx] == 1:\n",
    "            idx += 1             \n",
    "        images.append(original_image[start_idx-1:idx+1, :])       \n",
    "    return images[:-1]\n",
    "\n",
    "\n",
    "def find_split_points(image_list):\n",
    "    split_points = [] \n",
    "    \n",
    "    total_height = sum(img.shape[0] for img in image_list)\n",
    "    average_height = int(total_height / len(image_list))\n",
    "\n",
    "    for idx, img in enumerate(image_list):        \n",
    "        if img.shape[0] - average_height > average_height/2:  \n",
    "            middle_row = img.shape[0] // 2\n",
    "            num_rows_to_check = int(img.shape[0] * 0.1) \n",
    "            \n",
    "            min_black_pixels = float('inf')\n",
    "            max_white_length = 0\n",
    "            target_row = middle_row\n",
    "            \n",
    "            for i in range(middle_row - num_rows_to_check, middle_row + num_rows_to_check + 1):\n",
    "                row = img[i]\n",
    "                black_pixels = np.count_nonzero(row == 0)\n",
    "                white_lengths = [len(white) for white in ''.join(map(str, row)).split('0')]\n",
    "                if len(white_lengths) > 0:\n",
    "                    white_length = max(white_lengths)\n",
    "                else:\n",
    "                    white_length = 0\n",
    "                \n",
    "                if black_pixels < min_black_pixels and white_length > max_white_length:\n",
    "                    min_black_pixels = black_pixels\n",
    "                    max_white_length = white_length\n",
    "                    target_row = i\n",
    "                       \n",
    "            direction = -1 if min_black_pixels < (img.shape[0] - target_row - 1) else 1\n",
    "            \n",
    "            while True:\n",
    "                row = img[target_row]\n",
    "                black_pixels = np.count_nonzero(row == 0)\n",
    "                white_lengths = [len(white) for white in ''.join(map(str, row)).split('0')]\n",
    "                if len(white_lengths) > 0:\n",
    "                    white_length = max(white_lengths)\n",
    "                else:\n",
    "                    white_length = 0\n",
    "               \n",
    "                if black_pixels < min_black_pixels and white_length > max_white_length:\n",
    "                    min_black_pixels = black_pixels\n",
    "                    max_white_length = white_length\n",
    "                    target_row += direction\n",
    "                else:\n",
    "                    break  \n",
    "           \n",
    "            split_points.append((idx, target_row))\n",
    "    \n",
    "    return split_points\n",
    "\n",
    "def split_images(image_list, split_points):\n",
    "    new_image_list = []\n",
    " \n",
    "    split_points.sort(key=lambda x: x[0])\n",
    "   \n",
    "    for idx, img in enumerate(image_list):\n",
    "       \n",
    "        current_split_point = next((point[1] for point in split_points if point[0] == idx), None)\n",
    "                \n",
    "        if current_split_point is None:\n",
    "           \n",
    "            new_image_list.append(img)\n",
    "        else:           \n",
    "            upper_half = img[:current_split_point]\n",
    "            lower_half = img[current_split_point:]\n",
    "            new_image_list.extend([upper_half, lower_half])\n",
    "\n",
    "    return new_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 17:19:34.832020082 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:541 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/reference/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.\n"
     ]
    }
   ],
   "source": [
    "bounding_boxes = detect_text(image, model, threshold, padding)\n",
    "img_with_bounding_box = detection_visualize(image, bounding_boxes,no_label=True,text_padding=10)\n",
    "img_with_bounding_box.save(\"segmented_img.png\")\n",
    "image_cv2 = cv2.imread(input_file_name)\n",
    "   \n",
    "processed_image = preprocess_image(\"segmented_img.png\")\n",
    "    \n",
    "text_lines = find_text_lines(processed_image)\n",
    "   \n",
    "extracted_text = extract_text_regions(processed_image, text_lines)\n",
    "lines = []\n",
    "for i, outlier_img in enumerate(split_images(extract_text_regions(image_cv2, text_lines),find_split_points(extracted_text)), start=1):\n",
    "    cv2.imwrite(f\"line{i}.png\", outlier_img)\n",
    "    pil_img = Image.fromarray(outlier_img)\n",
    "    lines.append(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math detection and text OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentBlock:\n",
    "    def __init__(self,is_math:bool,latex_code:str,bounding_box:list,image:PIL.Image):\n",
    "        self.is_math = is_math\n",
    "        self.latex_code = latex_code\n",
    "        self.bounding_box = bounding_box    \n",
    "        self.image = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td># #</td>\n",
       "      <td>11464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td># #</td>\n",
       "      <td>6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>n (</td>\n",
       "      <td>3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>( #</td>\n",
       "      <td>3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>( #</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>) #</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>) -</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>( a</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td># (</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s (</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>in (</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>) #</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>000</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>) -</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>sin</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td># a</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td># )</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>an (</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td># )</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-4ac</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pattern  counter\n",
       "46      # #    11464\n",
       "47     # #      6953\n",
       "142    n (      3417\n",
       "22      ( #     3012\n",
       "23     ( #      2439\n",
       "19      ) #     2205\n",
       "41      ) -     1596\n",
       "61      ( a     1052\n",
       "25     # (      1015\n",
       "20     s (       989\n",
       "383    in (      867\n",
       "52     ) #       755\n",
       "92     000       649\n",
       "42     ) -       623\n",
       "382    sin       597\n",
       "57      # a      419\n",
       "53      # )      377\n",
       "430    an (      339\n",
       "54     # )       339\n",
       "259    -4ac      305"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_df = pd.read_csv(\"patterns.csv\")\n",
    "pattern_df = pattern_df.sort_values(by=[\"counter\"], ascending=False)\n",
    "pattern_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.weight', 'encoder.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_OCR(img):\n",
    "    pixel_values = processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(generated_text)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_patterns_in_string(text, cutoff = .3,max_char_distance=4):\n",
    "    pattern_df = pd.read_csv(\"patterns.csv\")\n",
    "    patterns_as_list = pattern_df['pattern'].to_list()\n",
    "    print(f\"Checking patterns in '{text}'\")\n",
    "    \n",
    "    found_patterns = []\n",
    "    pattern_len = len(patterns_as_list[0])\n",
    "    text_len = len(text)\n",
    "    possible_pattern_count = text_len-pattern_len+1\n",
    "    print(f\"text_len: {text_len}, possible_pattern_count: {possible_pattern_count}\")\n",
    "\n",
    "    for pattern in patterns_as_list:\n",
    "        if (pattern in text):\n",
    "            found_patterns.append(pattern)\n",
    "    print(f\"\\nfound {len(found_patterns)} patterns in the text\")\n",
    "    print(found_patterns)\n",
    "    \n",
    "    if (round(possible_pattern_count * cutoff) <= len(found_patterns)):\n",
    "        # check distance of words\n",
    "        start_indexes = []\n",
    "        min_num_of_close = len(found_patterns) / 3\n",
    "        num_of_close = 0\n",
    "        for pattern in found_patterns:\n",
    "            start_index = text.find(pattern)\n",
    "            start_indexes.append(start_index)\n",
    "            if len(start_indexes)!=0:\n",
    "                char_distance = start_index - start_indexes[-1]\n",
    "                if max_char_distance >= char_distance:\n",
    "                    num_of_close = num_of_close+1\n",
    "        if num_of_close >= min_num_of_close:\n",
    "            print(\"its METH\")\n",
    "            return \"math\"\n",
    "        else:\n",
    "            print(\"its METH and text\")\n",
    "            return \"mixed\" # its mixed it has both text and math\n",
    "\n",
    "    elif (round(possible_pattern_count * cutoff) > len(found_patterns)):\n",
    "        return \"text\"\n",
    "    else:\n",
    "        return \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "progress: 1/17\n",
      "1.3. CONVOLUTIONS AND GENERALIZED FCTS.\n",
      "Checking patterns in '1.3. CONVOLUTIONS AND GENERALIZED FCTS.'\n",
      "text_len: 39, possible_pattern_count: 36\n",
      "\n",
      "found 0 patterns in the text\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "progress: 2/17\n",
      "Def. \" Given two functions of and g, the\n",
      "Checking patterns in 'Def. \" Given two functions of and g, the'\n",
      "text_len: 40, possible_pattern_count: 37\n",
      "\n",
      "found 4 patterns in the text\n",
      "['ven ', ' the', ' and', 'and ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 3/17\n",
      "convolution of f and g is the function.\n",
      "Checking patterns in 'convolution of f and g is the function.'\n",
      "text_len: 39, possible_pattern_count: 36\n",
      "\n",
      "found 5 patterns in the text\n",
      "[' is ', ' the', 'the ', ' and', 'and ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 4/17\n",
      "densted by ftg and defined by\n",
      "Checking patterns in 'densted by ftg and defined by'\n",
      "text_len: 29, possible_pattern_count: 26\n",
      "\n",
      "found 2 patterns in the text\n",
      "[' and', 'and ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 5/17\n",
      "# ( f mg ( A ) - ( ft-xinglox dx.\n",
      "Checking patterns in '# ( f mg ( A ) - ( ft-xinglox dx.'\n",
      "text_len: 33, possible_pattern_count: 30\n",
      "\n",
      "found 6 patterns in the text\n",
      "[' - (', '- ( ', '# ( ', ' ) -', ') - ', ' dx.']\n",
      "\n",
      "\n",
      "\n",
      "progress: 6/17\n",
      "the abuse of notation ( # gives # fit # gets\n",
      "Checking patterns in 'the abuse of notation ( # gives # fit # gets'\n",
      "text_len: 44, possible_pattern_count: 41\n",
      "\n",
      "found 8 patterns in the text\n",
      "[' ( #', '( # ', 't # ', 'n ( ', 'the ', 'on (', ' not', 's # ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 7/17\n",
      "1940 is autonomy and convenient\n",
      "Checking patterns in '1940 is autonomy and convenient'\n",
      "text_len: 31, possible_pattern_count: 28\n",
      "\n",
      "found 3 patterns in the text\n",
      "[' is ', ' and', 'and ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 8/17\n",
      "Then 1.13. For any two functions f and g. fpg.g.f\n",
      "Checking patterns in 'Then 1.13. For any two functions f and g. fpg.g.f'\n",
      "text_len: 49, possible_pattern_count: 46\n",
      "\n",
      "found 4 patterns in the text\n",
      "[' and', 'and ', ' any', 'any ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 9/17\n",
      "Then 114 THE CONVOLUTION THEOREM\n",
      "Checking patterns in 'Then 114 THE CONVOLUTION THEOREM'\n",
      "text_len: 32, possible_pattern_count: 29\n",
      "\n",
      "found 0 patterns in the text\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "progress: 10/17\n",
      "Supposed that if and your piecewise\n",
      "Checking patterns in 'Supposed that if and your piecewise'\n",
      "text_len: 35, possible_pattern_count: 32\n",
      "\n",
      "found 3 patterns in the text\n",
      "[' you', ' and', 'and ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 11/17\n",
      "continuous and of exponential order.\n",
      "Checking patterns in 'continuous and of exponential order.'\n",
      "text_len: 36, possible_pattern_count: 33\n",
      "\n",
      "found 2 patterns in the text\n",
      "[' and', 'and ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 12/17\n",
      "with LYLE ) - FLA ) for 4.2C.30 and\n",
      "Checking patterns in 'with LYLE ) - FLA ) for 4.2C.30 and'\n",
      "text_len: 35, possible_pattern_count: 32\n",
      "\n",
      "found 4 patterns in the text\n",
      "[' ) -', ') - ', ' and', 'E ) ']\n",
      "\n",
      "\n",
      "\n",
      "progress: 13/17\n",
      "LIGHTS - G.41 )ONS rec.30. Then frig-\n",
      "Checking patterns in 'LIGHTS - G.41 )ONS rec.30. Then frig-'\n",
      "text_len: 37, possible_pattern_count: 34\n",
      "\n",
      "found 0 patterns in the text\n",
      "[]\n",
      "\n",
      "\n",
      "\n",
      "progress: 14/17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_102444/68056283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"progress: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_OCR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_patterns_in_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_char_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_102444/371076743.py\u001b[0m in \u001b[0;36mtext_OCR\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext_OCR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m-> 1330\u001b[0;31m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         )\n\u001b[1;32m    594\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 )\n\u001b[1;32m    412\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# second residual connection is done here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/transformers/models/vit/modeling_vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/.venv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "total = str(len(lines))\n",
    "for line in lines:\n",
    "    i=i+1\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"progress: \"+str(i)+\"/\"+total)\n",
    "    text = text_OCR(line)\n",
    "    img_type=check_patterns_in_string(text,cutoff=0.6,max_char_distance=10)\n",
    "    if img_type == \"text\":\n",
    "        blocks.append(DocumentBlock(is_math=False,latex_code=\"\\\\par\"+text,bounding_box=\"\",image=line))\n",
    "    else:\n",
    "        blocks.append(DocumentBlock(is_math=True,latex_code=\"\",bounding_box=\"\",image=line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do math OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akos/Documents/GitHub/experiments/handwritten/Handwritten_pipeline/BTTR\n"
     ]
    }
   ],
   "source": [
    "%cd BTTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-19 17:23:32--  https://github.com/Green-Wood/BTTR/releases/download/v2.0/pretrained-2014.ckpt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/359744542/743ebf80-ce10-11eb-9560-9814ca05d92f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240519%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240519T152333Z&X-Amz-Expires=300&X-Amz-Signature=1ad5d809b51e076e16125a619ee2b3053e62bcb4bd781fd856336899d7882510&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=359744542&response-content-disposition=attachment%3B%20filename%3Dpretrained-2014.ckpt&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-05-19 17:23:33--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/359744542/743ebf80-ce10-11eb-9560-9814ca05d92f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240519%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240519T152333Z&X-Amz-Expires=300&X-Amz-Signature=1ad5d809b51e076e16125a619ee2b3053e62bcb4bd781fd856336899d7882510&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=359744542&response-content-disposition=attachment%3B%20filename%3Dpretrained-2014.ckpt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Green-Wood/BTTR/releases/download/v2.0/pretrained-2014.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bttr.lit_bttr import LitBTTR\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt= \"./pretrained-2014.ckpt\"\n",
    "test_year = \"2014\"\n",
    "model_math = LitBTTR.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_img(img):\n",
    "    thresh = 210\n",
    "    fn = lambda x : 0 if x > thresh else 255\n",
    "    img = img.convert('L').point(fn, mode='1')\n",
    "    display(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_OCR(img,beam_size=22,max_len = 350,alpha  = 1.0):\n",
    "    img = ToTensor()(img)\n",
    "    # increased beam sized results in better result, but slower performance\n",
    "    hyp = model_math.beam_search(\n",
    "    img=img, \n",
    "    beam_size=beam_size,\n",
    "    max_len = max_len,\n",
    "    alpha  = alpha)\n",
    "    print(hyp)\n",
    "    return hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(blocks)):\n",
    "    print(blocks[i].is_math)\n",
    "    if blocks[i].is_math:\n",
    "        print(\"math found\")\n",
    "        block = blocks[i]\n",
    "        binary_img = binarize_img(block.image)\n",
    "        block.latex_code = math_OCR(binary_img)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
